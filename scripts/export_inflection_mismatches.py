# Path: scripts/export_inflection_mismatches.py
import sqlite3
import csv
import re
import time
import multiprocessing
from pathlib import Path
from bs4 import BeautifulSoup
from concurrent.futures import ProcessPoolExecutor, as_completed

# C·∫•u h√¨nh
DB_PATH = Path('data/dpd/dpd.db')
TMP_DIR = Path('tmp')
OUTPUT_FILE = TMP_DIR / 'inflection_mismatches.csv'
BATCH_SIZE = 2500  # S·ªë l∆∞·ª£ng d√≤ng m·ªói process x·ª≠ l√Ω 1 l·∫ßn

def setup_environment():
    if not TMP_DIR.exists():
        TMP_DIR.mkdir(parents=True)

def normalize_word(word):
    return word.strip()

def clean_lemma_key(lemma):
    return re.sub(r'\s\d+(\.\d+)?$', '', lemma)

def extract_from_html(html_content):
    """
    Tr√≠ch xu·∫•t t·ª´ bi·∫øn th·ªÉ t·ª´ HTML (Logic Robust v2).
    H√†m n√†y ph·∫£i ƒë·ªôc l·∫≠p ƒë·ªÉ c√≥ th·ªÉ pickle qua c√°c process.
    """
    if not html_content:
        return set()

    soup = BeautifulSoup(html_content, 'html.parser')
    words = set()

    table = soup.find('table', class_='inflection')
    if not table:
        return words

    BR_MARKER = "###BR###"

    for td in table.find_all('td'):
        for br in td.find_all('br'):
            br.replace_with(BR_MARKER)
        for b in td.find_all('b'):
            b.unwrap()

        text = td.get_text(strip=True)
        text = text.replace(BR_MARKER, " ")
        tokens = text.split()
        
        for token in tokens:
            clean_w = re.sub(r'[^\wƒÅƒ´≈´·πÖ√±·π≠·∏ç·πá·∏∑·πÉ·πÅƒÄƒ™≈™·πÑ√ë·π¨·∏å·πÜ·∏∂·πÇ·πÄ]', '', token)
            if clean_w:
                words.add(clean_w)
    return words

def process_batch(rows):
    """
    Worker function: X·ª≠ l√Ω m·ªôt l√¥ d·ªØ li·ªáu.
    Input: List of dicts/tuples (NOT sqlite3.Row objects).
    Output: List of mismatched rows.
    """
    mismatches = []
    
    for row in rows:
        # row structure: (id, lemma_1, stem, pattern, inflections, inflections_thai, inflections_html)
        r_id, lemma_1, stem, pattern, inflections, inf_thai, inf_html = row
        
        # --- L·ªåC B·ªé STEM ƒê·∫∂C BI·ªÜT ---
        # B·ªè qua n·∫øu stem b·∫Øt ƒë·∫ßu b·∫±ng '!' ho·∫∑c '-'
        if stem and (stem.startswith('!') or stem.startswith('-')):
            continue
        
        lemma_clean = clean_lemma_key(lemma_1)

        # 1. Parse CSV
        csv_raw = inflections.split(',')
        set_csv = {normalize_word(w) for w in csv_raw if w.strip()}
        
        # 2. Parse HTML
        set_html = extract_from_html(inf_html)
        
        # 3. Discard lemma
        set_csv.discard(lemma_clean)
        set_html.discard(lemma_clean)

        # 4. Compare
        missing = set_csv - set_html
        extra = set_html - set_csv

        if missing or extra:
            mismatches.append([
                r_id,
                lemma_1,
                stem,
                pattern,
                inflections,
                inf_thai,
                inf_html,
                ", ".join(missing),
                ", ".join(extra)
            ])
            
    return mismatches

def scan_and_export_parallel():
    setup_environment()
    start_time = time.time()
    
    # X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng CPU
    max_workers = multiprocessing.cpu_count()
    print(f"üöÄ B·∫Øt ƒë·∫ßu qu√©t ƒëa lu·ªìng tr√™n {max_workers} nh√¢n CPU.")
    print(f"üì¶ Batch Size: {BATCH_SIZE}")

    try:
        conn = sqlite3.connect(DB_PATH)
        # Kh√¥ng d√πng Row factory ƒë·ªÉ d·ªÖ convert sang tuple cho multiprocessing
        cursor = conn.cursor()

        # ƒê·∫øm t·ªïng s·ªë d√≤ng ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng (ƒë√£ l·ªçc ƒëi·ªÅu ki·ªán c∆° b·∫£n)
        print("‚ö° ƒêang ƒë·∫øm t·ªïng s·ªë b·∫£n ghi...")
        cursor.execute("SELECT Count(*) FROM dpd_headwords WHERE inflections IS NOT NULL AND inflections != ''")
        total_records = cursor.fetchone()[0]
        print(f"‚ö° T·ªïng c·ªông: {total_records} d√≤ng c·∫ßn x·ª≠ l√Ω (ch∆∞a l·ªçc stem).")

        # Query ch√≠nh
        sql = """
            SELECT id, lemma_1, stem, pattern, inflections, inflections_thai, inflections_html 
            FROM dpd_headwords 
            WHERE inflections IS NOT NULL 
              AND inflections_html IS NOT NULL 
              AND inflections != ''
        """
        cursor.execute(sql)
        
        total_mismatches = 0
        processed_count = 0

        with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['id', 'lemma_1', 'stem', 'pattern', 'inflections', 'inflections_thai', 'inflections_html', 'missing_in_html', 'extra_in_html'])

            # S·ª≠ d·ª•ng ProcessPoolExecutor
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                
                while True:
                    # Fetch batch t·ª´ DB (Main Thread l√†m vi·ªác n√†y r·∫•t nhanh)
                    db_rows = cursor.fetchmany(BATCH_SIZE)
                    if not db_rows:
                        break
                    
                    # Submit job cho worker
                    future = executor.submit(process_batch, db_rows)
                    futures.append(future)

                print("‚ö° ƒê√£ g·ª≠i to√†n b·ªô task, ƒëang ch·ªù x·ª≠ l√Ω...")

                # Thu th·∫≠p k·∫øt qu·∫£ khi ho√†n th√†nh
                for future in as_completed(futures):
                    try:
                        batch_results = future.result()
                        if batch_results:
                            writer.writerows(batch_results)
                            total_mismatches += len(batch_results)
                        
                        processed_count += BATCH_SIZE
                        # Progress log ƒë∆°n gi·∫£n
                        if processed_count % (BATCH_SIZE * 4) == 0:
                            percent = min(100, (processed_count / total_records) * 100)
                            print(f"   ... {percent:.1f}% - ƒê√£ t√¨m th·∫•y {total_mismatches} l·ªói.")
                            
                    except Exception as e:
                        print(f"‚ùå L·ªói trong worker: {e}")

        duration = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"‚úÖ HO√ÄN T·∫§T SAU {duration:.2f} GI√ÇY.")
        print(f"   - T·ªïng s·ªë d√≤ng sai l·ªách: {total_mismatches}")
        print(f"   - File k·∫øt qu·∫£:          {OUTPUT_FILE}")
        print(f"{'='*60}")

    except sqlite3.Error as e:
        print(f"‚ùå L·ªói Database: {e}")
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    scan_and_export_parallel()