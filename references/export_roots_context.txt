dpd-db/
├── db/
│   ├── db_helpers.py
│   └── models.py
├── exporter/
│   └── goldendict/
│       ├── export_roots.py
│       └── helpers.py
└── tools/
    ├── cache_load.py
    ├── configger.py
    ├── css_manager.py
    ├── date_and_time.py
    ├── degree_of_completion.py
    ├── goldendict_exporter.py
    ├── goldendict_path.py
    ├── lemma_traditional.py
    ├── meaning_construction.py
    ├── niggahitas.py
    ├── pali_sort_key.py
    ├── paths.py
    ├── pos.py
    ├── printer.py
    ├── sinhala_tools.py
    ├── sutta_codes.py
    └── utils.py

================================================================================

<file path="db/db_helpers.py">
"""DB related functions:
1. Create db if doesn't already exist,
2. Create db Session
3. Get column names,
4. Print column names.
"""

import os
import sys
from pathlib import Path

from sqlalchemy import create_engine, inspect
from sqlalchemy.orm import Session, sessionmaker

from db.models import Base
from tools.printer import printer as pr


def create_db_if_not_exists(db_path: Path):
    """Create the db if it does not exist already."""
    engine = create_engine(f"sqlite+pysqlite:///{db_path}", echo=False)
    if not db_path.is_file():
        Base.metadata.create_all(bind=engine)


def create_tables(db_path: Path):
    """Create tables if they don't exist."""
    engine = create_engine(f"sqlite+pysqlite:///{db_path}", echo=False)
    Base.metadata.create_all(bind=engine)


def get_db_session(db_path: Path) -> Session:
    """Get the db session, used ubiquitously."""
    if not os.path.isfile(db_path):
        pr.red(f"Database file doesn't exist: {db_path}")
        sys.exit(1)

    try:
        db_eng = create_engine(f"sqlite+pysqlite:///{db_path}", echo=False)
        # db_conn = db_eng.connect()

        Session = sessionmaker(db_eng)
        Session.configure(bind=db_eng)
        db_sess = Session()

    except Exception as e:
        pr.red(f"Can't connect to database: {e}")
        sys.exit(1)

    return db_sess


def print_column_names(tables_name):
    """Print a numbered list of all the column names in a given table."""

    inspector = inspect(tables_name)
    column_names = [column.name for column in inspector.columns]
    for counter, column_name in enumerate(column_names):
        print(f"{counter}. {column_name}")


def get_column_names(tables_name):
    inspector = inspect(tables_name)
    column_names = [column.name for column in inspector.columns]
    return column_names

</file>


<file path="db/models.py">
"""Database model for use by SQLAlchemy."""

import json
import re
from typing import List, Optional

from sqlalchemy import DateTime, ForeignKey, and_, case, null, or_
from sqlalchemy.ext.hybrid import hybrid_property
from sqlalchemy.orm import (
    DeclarativeBase,
    Mapped,
    foreign,
    mapped_column,
    object_session,
    relationship,
)
from sqlalchemy.sql import func

from tools.pali_sort_key import pali_sort_key
from tools.pos import CONJUGATIONS, DECLENSIONS, EXCLUDE_FROM_FREQ


class Base(DeclarativeBase):
    pass


class DbInfo(Base):
    """
    Store general key-value data such as
    1. dpd_db info, release_version, etc
    2. cached values, cf_set, etc.
    """

    __tablename__ = "db_info"
    id: Mapped[int] = mapped_column(primary_key=True)
    key: Mapped[str] = mapped_column(unique=True)
    value: Mapped[str] = mapped_column(default="")

    # value pack unpack
    def value_pack(self, data) -> None:
        self.value = json.dumps(data, ensure_ascii=False)

    @property
    def value_unpack(self) -> list[str]:
        return json.loads(self.value)


class InflectionTemplates(Base):
    """Inflection templates for generating html tables."""

    __tablename__ = "inflection_templates"
    pattern: Mapped[str] = mapped_column(primary_key=True)
    like: Mapped[str] = mapped_column(default="")
    data: Mapped[str] = mapped_column(default="")

    # inflection templates pack unpack
    def inflection_template_pack(self, list: list[str]) -> None:
        self.data = json.dumps(list, ensure_ascii=False)

    @property
    def inflection_template_unpack(self) -> list[str]:
        return json.loads(self.data)

    def __repr__(self) -> str:
        return f"InflectionTemplates: {self.pattern} {self.like} {self.data}"


class DpdRoot(Base):
    __tablename__ = "dpd_roots"

    root: Mapped[str] = mapped_column(primary_key=True)
    root_in_comps: Mapped[str] = mapped_column(default="")
    root_has_verb: Mapped[str] = mapped_column(default="")
    root_group: Mapped[int] = mapped_column(default=0)
    root_sign: Mapped[str] = mapped_column(default="")
    root_meaning: Mapped[str] = mapped_column(default="")
    sanskrit_root: Mapped[str] = mapped_column(default="")
    sanskrit_root_meaning: Mapped[str] = mapped_column(default="")
    sanskrit_root_class: Mapped[str] = mapped_column(default="")
    root_example: Mapped[str] = mapped_column(default="")
    dhatupatha_num: Mapped[str] = mapped_column(default="")
    dhatupatha_root: Mapped[str] = mapped_column(default="")
    dhatupatha_pali: Mapped[str] = mapped_column(default="")
    dhatupatha_english: Mapped[str] = mapped_column(default="")
    dhatumanjusa_num: Mapped[int] = mapped_column(default=0)
    dhatumanjusa_root: Mapped[str] = mapped_column(default="")
    dhatumanjusa_pali: Mapped[str] = mapped_column(default="")
    dhatumanjusa_english: Mapped[str] = mapped_column(default="")
    dhatumala_root: Mapped[str] = mapped_column(default="")
    dhatumala_pali: Mapped[str] = mapped_column(default="")
    dhatumala_english: Mapped[str] = mapped_column(default="")
    panini_root: Mapped[str] = mapped_column(default="")
    panini_sanskrit: Mapped[str] = mapped_column(default="")
    panini_english: Mapped[str] = mapped_column(default="")
    note: Mapped[str] = mapped_column(default="")
    matrix_test: Mapped[str] = mapped_column(default="")
    root_info: Mapped[str] = mapped_column(default="")
    root_matrix: Mapped[str] = mapped_column(default="")

    created_at: Mapped[Optional[DateTime]] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )
    updated_at: Mapped[Optional[DateTime]] = mapped_column(
        DateTime(timezone=True), onupdate=func.now()
    )

    pw: Mapped[List["DpdHeadword"]] = relationship(back_populates="rt")

    @property
    def root_clean(self) -> str:
        """Remove digits from the end"""
        return re.sub(r" \d.*$", "", self.root)

    @property
    def root_no_sign(self) -> str:
        """Remove digits from the end and root sign"""
        return re.sub(r"\d| |√", "", self.root)

    @property
    def root_(self) -> str:
        """Replace whitespace with underscores"""
        return self.root.replace(" ", "_")

    @property
    def root_no_sign_(self) -> str:
        """Remove root sign and replace whitespace with underscores.
        Useful for html links."""
        return self.root.replace(" ", "_").replace("√", "")

    @property
    def root_link(self) -> str:
        return self.root.replace(" ", "%20")

    @property
    def root_count(self) -> int:
        db_session = object_session(self)
        if db_session is None:
            raise Exception("No db_session")

        return (
            db_session.query(DpdHeadword)
            .filter(DpdHeadword.root_key == self.root)
            .count()
        )

    @property
    def root_family_list(self) -> list:
        db_session = object_session(self)
        if db_session is None:
            raise Exception("No db_session")

        results = (
            db_session.query(DpdHeadword)
            .filter(DpdHeadword.root_key == self.root)
            .group_by(DpdHeadword.family_root)
            .all()
        )
        family_list = [i.family_root for i in results if i.family_root is not None]
        family_list = sorted(family_list, key=lambda x: pali_sort_key(x))
        return family_list

    def __repr__(self) -> str:
        return f"""DpdRoot: {self.root} {self.root_group} {self.root_sign} ({self.root_meaning})"""


class FamilyRoot(Base):
    __tablename__ = "family_root"
    root_family_key: Mapped[str] = mapped_column(primary_key=True)
    root_key: Mapped[str] = mapped_column(primary_key=True)
    root_family: Mapped[str] = mapped_column(default="")
    root_meaning: Mapped[str] = mapped_column(default="")
    html: Mapped[str] = mapped_column(default="")
    data: Mapped[str] = mapped_column(default="")
    count: Mapped[int] = mapped_column(default=0)

    # root family pack unpack
    def data_pack(self, list: list[str]) -> None:
        self.data = json.dumps(list, ensure_ascii=False, indent=1)

    @property
    def data_unpack(self) -> list[str]:
        return json.loads(self.data)

    @property
    def root_family_link(self) -> str:
        return self.root_family.replace(" ", "%20")

    @property
    def root_family_(self) -> str:
        return self.root_family.replace(" ", "_")

    @property
    def root_family_clean(self) -> str:
        """Remove root sign"""
        return self.root_family.replace("√", "")

    @property
    def root_family_clean_no_space(self) -> str:
        """Remove root sign and space"""
        return self.root_family.replace("√", "").replace(" ", "")

    @property
    def root_family_key_typst(self) -> str:
        return self.root_family_key.replace(" ", "_").replace("√", "")

    def __repr__(self) -> str:
        return f"FamilyRoot: {self.root_family_key} {self.count}"


class Lookup(Base):
    __tablename__ = "lookup"

    lookup_key: Mapped[str] = mapped_column(primary_key=True)
    headwords: Mapped[str] = mapped_column(default="")
    roots: Mapped[str] = mapped_column(default="")
    deconstructor: Mapped[str] = mapped_column(default="")
    variant: Mapped[str] = mapped_column(default="")
    spelling: Mapped[str] = mapped_column(default="")
    grammar: Mapped[str] = mapped_column(default="")
    help: Mapped[str] = mapped_column(default="")
    abbrev: Mapped[str] = mapped_column(default="")
    epd: Mapped[str] = mapped_column(default="")
    rpd: Mapped[str] = mapped_column(default="")
    other: Mapped[str] = mapped_column(default="")
    sinhala: Mapped[str] = mapped_column(default="")
    devanagari: Mapped[str] = mapped_column(default="")
    thai: Mapped[str] = mapped_column(default="")

    # headwords pack unpack

    def headwords_pack(self, list: list[int]) -> None:
        if list:
            self.headwords = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def headwords_unpack(self) -> list[int]:
        if self.headwords:
            return json.loads(self.headwords)
        else:
            return []

    # roots pack unpack

    def roots_pack(self, list: list[str]) -> None:
        if list:
            self.roots = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def roots_unpack(self) -> list[str]:
        if self.roots:
            return json.loads(self.roots)
        else:
            return []

    # deconstructor pack unpack

    def deconstructor_pack(self, list: list[str]) -> None:
        if list:
            self.deconstructor = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def deconstructor_unpack(self) -> list[str]:
        if self.deconstructor:
            return json.loads(self.deconstructor)
        else:
            return []

    # variants pack unpack

    def variants_pack(self, dict) -> None:
        if dict:
            self.variant = json.dumps(dict, ensure_ascii=False)
        else:
            raise ValueError("A dict must be provided to pack.")

    @property
    def variants_unpack(self) -> dict:
        if self.variant:
            return json.loads(self.variant)
        else:
            return {}

    # spelling pack unpack

    def spelling_pack(self, list: list[str]) -> None:
        if list:
            self.spelling = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def spelling_unpack(self) -> list[str]:
        if self.spelling:
            return json.loads(self.spelling)
        else:
            return []

    # grammar pack unpack
    # TODO add a method to unpack to html

    def grammar_pack(self, list: list[tuple[str, str, str]]) -> None:
        if list:
            self.grammar = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def grammar_unpack(self) -> list[str]:
        if self.grammar:
            return json.loads(self.grammar)
        else:
            return []

    # help pack unpack

    def help_pack(self, string: str) -> None:
        if string:
            self.help = json.dumps(string, ensure_ascii=False)
        else:
            raise ValueError("A string must be provided to pack.")

    @property
    def help_unpack(self) -> str:
        if self.help:
            return json.loads(self.help)
        else:
            return ""

    # abbreviations pack unpack

    def abbrev_pack(self, dict: dict[str, str]) -> None:
        if dict:
            self.abbrev = json.dumps(dict, ensure_ascii=False, indent=1)
        else:
            raise ValueError("A dict must be provided to pack.")

    @property
    def abbrev_unpack(self) -> dict[str, str]:
        if self.abbrev:
            return json.loads(self.abbrev)
        else:
            return {}

    # epd pack unpack

    def epd_pack(self, list: list[tuple[str, str, str]]) -> None:
        if dict:
            self.epd = json.dumps(list, ensure_ascii=False, indent=1)
        else:
            raise ValueError("A dict must be provided to pack.")

    @property
    def epd_unpack(self) -> list[tuple[str, str, str]]:
        if self.epd:
            return json.loads(self.epd)
        else:
            return []

    # rpd pack unpack

    def rpd_pack(self, list: list[tuple[str, str, str]]) -> None:
        if dict:
            self.rpd = json.dumps(list, ensure_ascii=False, indent=1)
        else:
            raise ValueError("A dict must be provided to pack.")

    @property
    def rpd_unpack(self) -> list[tuple[str, str, str]]:
        if self.rpd:
            return json.loads(self.rpd)
        else:
            return []

    # pack unpack sinhala

    def sinhala_pack(self, list: list[str]) -> None:
        if list:
            self.sinhala = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def sinhala_unpack(self) -> list[str]:
        if self.sinhala:
            return json.loads(self.sinhala)
        else:
            return []

    # pack unpack devanagari

    def devanagari_pack(self, list: list[str]) -> None:
        if list:
            self.devanagari = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def devanagari_unpack(self) -> list[str]:
        if self.devanagari:
            return json.loads(self.devanagari)
        else:
            return []

    # pack unpack thai

    def thai_pack(self, list: list[str]) -> None:
        if list:
            self.thai = json.dumps(list, ensure_ascii=False)
        else:
            raise ValueError("A list must be provided to pack.")

    @property
    def thai_unpack(self) -> list[str]:
        if self.thai:
            return json.loads(self.thai)
        else:
            return []

    def __repr__(self) -> str:
        return f"""
key:           {self.lookup_key}
headwords:     {self.headwords}
roots:         {self.roots}
deconstructor: {self.deconstructor}
variant:       {self.variant}
spelling:      {self.spelling}
grammar:       {self.grammar}
help:          {self.help}
abbrev:        {self.abbrev}
sinhala:       {self.sinhala}
devanagari:    {self.devanagari}
thai:          {self.thai}
"""


# class PaliWord(Base):
#     """DO NOT USE !!! JUST FOR CONVERTING OLD FILE FORMATS !!!"""
#     __tablename__ = "pali_words"

#     id: Mapped[int] = mapped_column(primary_key=True)
#     pali_1: Mapped[str] = mapped_column(unique=True)
#     pali_2: Mapped[str] = mapped_column(default='')
#     pos: Mapped[str] = mapped_column(default='')
#     grammar: Mapped[str] = mapped_column(default='')
#     derived_from: Mapped[str] = mapped_column(default='')
#     neg: Mapped[str] = mapped_column(default='')
#     verb: Mapped[str] = mapped_column(default='')
#     trans:  Mapped[str] = mapped_column(default='')
#     plus_case:  Mapped[str] = mapped_column(default='')

#     meaning_1: Mapped[str] = mapped_column(default='')
#     meaning_lit: Mapped[str] = mapped_column(default='')
#     meaning_2: Mapped[str] = mapped_column(default='')

#     non_ia: Mapped[str] = mapped_column(default='')
#     sanskrit: Mapped[str] = mapped_column(default='')

#     root_key: Mapped[str] = mapped_column(default='')
#     root_sign: Mapped[str] = mapped_column(default='')
#     root_base: Mapped[str] = mapped_column(default='')

#     family_root: Mapped[str] = mapped_column(default='')
#     family_word: Mapped[str] = mapped_column(default='')
#     family_compound: Mapped[str] = mapped_column(default='')
#     family_set: Mapped[str] = mapped_column(default='')

#     construction:  Mapped[str] = mapped_column(default='')
#     derivative: Mapped[str] = mapped_column(default='')
#     suffix: Mapped[str] = mapped_column(default='')
#     phonetic: Mapped[str] = mapped_column(default='')
#     compound_type: Mapped[str] = mapped_column(default='')
#     compound_construction: Mapped[str] = mapped_column(default='')
#     non_root_in_comps: Mapped[str] = mapped_column(default='')

#     source_1: Mapped[str] = mapped_column(default='')
#     sutta_1: Mapped[str] = mapped_column(default='')
#     example_1: Mapped[str] = mapped_column(default='')

#     source_2: Mapped[str] = mapped_column(default='')
#     sutta_2: Mapped[str] = mapped_column(default='')
#     example_2: Mapped[str] = mapped_column(default='')

#     antonym: Mapped[str] = mapped_column(default='')
#     synonym: Mapped[str] = mapped_column(default='')
#     variant: Mapped[str] = mapped_column(default='')
#     commentary: Mapped[str] = mapped_column(default='')
#     notes: Mapped[str] = mapped_column(default='')
#     cognate: Mapped[str] = mapped_column(default='')
#     link: Mapped[str] = mapped_column(default='')
#     origin: Mapped[str] = mapped_column(default='')

#     stem: Mapped[str] = mapped_column(default='')
#     pattern: Mapped[str] = mapped_column(default='')

#     created_at: Mapped[Optional[DateTime]] = mapped_column(
#         DateTime(timezone=True), server_default=func.now())
#     updated_at: Mapped[Optional[DateTime]] = mapped_column(
#         DateTime(timezone=True), onupdate=func.now())


class SuttaInfo(Base):
    __tablename__ = "sutta_info"
    # dpd
    book: Mapped[str] = mapped_column(default="")
    book_code: Mapped[str] = mapped_column(default="")
    dpd_code: Mapped[str] = mapped_column(default="")
    dpd_sutta: Mapped[str] = mapped_column(primary_key=True)
    dpd_sutta_var: Mapped[str] = mapped_column(default="")
    # cst
    cst_code: Mapped[str] = mapped_column(default="")
    cst_nikaya: Mapped[str] = mapped_column(default="")
    cst_book: Mapped[str] = mapped_column(default="")
    cst_section: Mapped[str] = mapped_column(default="")
    cst_vagga: Mapped[str] = mapped_column(default="")
    cst_sutta: Mapped[str] = mapped_column(default="")
    cst_paranum: Mapped[str] = mapped_column(default="")
    cst_m_page: Mapped[str] = mapped_column(default="")
    cst_v_page: Mapped[str] = mapped_column(default="")
    cst_p_page: Mapped[str] = mapped_column(default="")
    cst_t_page: Mapped[str] = mapped_column(default="")
    cst_file: Mapped[str] = mapped_column(default="")
    # sutta central
    sc_code: Mapped[str] = mapped_column(default="")
    sc_book: Mapped[str] = mapped_column(default="")
    sc_vagga: Mapped[str] = mapped_column(default="")
    sc_sutta: Mapped[str] = mapped_column(default="")
    sc_eng_sutta: Mapped[str] = mapped_column(default="")
    sc_blurb: Mapped[str] = mapped_column(default="")
    # sc_card_link: Mapped[str] = mapped_column(default="")
    # sc_pali_link: Mapped[str] = mapped_column(default="")
    # sc_eng_link: Mapped[str] = mapped_column(default="")
    sc_file_path: Mapped[str] = mapped_column(default="")
    dpr_code: Mapped[str] = mapped_column(default="")
    dpr_link: Mapped[str] = mapped_column(default="")
    # bjt
    bjt_sutta_code: Mapped[str] = mapped_column(default="")
    bjt_web_code: Mapped[str] = mapped_column(default="")
    bjt_filename: Mapped[str] = mapped_column(default="")
    bjt_book_id: Mapped[str] = mapped_column(default="")
    bjt_page_num: Mapped[str] = mapped_column(default="")
    bjt_page_offset: Mapped[str] = mapped_column(default="")
    bjt_piṭaka: Mapped[str] = mapped_column(default="")
    bjt_nikāya: Mapped[str] = mapped_column(default="")
    bjt_major_section: Mapped[str] = mapped_column(default="")
    bjt_book: Mapped[str] = mapped_column(default="")
    bjt_minor_section: Mapped[str] = mapped_column(default="")
    bjt_vagga: Mapped[str] = mapped_column(default="")
    bjt_sutta: Mapped[str] = mapped_column(default="")

    dv_pts: Mapped[str] = mapped_column(default="")
    dv_main_theme: Mapped[str] = mapped_column(default="")
    dv_subtopic: Mapped[str] = mapped_column(default="")
    dv_summary: Mapped[str] = mapped_column(default="")
    dv_similes: Mapped[str] = mapped_column(default="")
    dv_key_excerpt1: Mapped[str] = mapped_column(default="")
    dv_key_excerpt2: Mapped[str] = mapped_column(default="")
    dv_stage: Mapped[str] = mapped_column(default="")
    dv_training: Mapped[str] = mapped_column(default="")
    dv_aspect: Mapped[str] = mapped_column(default="")
    dv_teacher: Mapped[str] = mapped_column(default="")
    dv_audience: Mapped[str] = mapped_column(default="")
    dv_method: Mapped[str] = mapped_column(default="")
    dv_length: Mapped[str] = mapped_column(default="")
    dv_prominence: Mapped[str] = mapped_column(default="")
    dv_nikayas_parallels: Mapped[str] = mapped_column(default="")
    dv_āgamas_parallels: Mapped[str] = mapped_column(default="")
    dv_taisho_parallels: Mapped[str] = mapped_column(default="")
    dv_sanskrit_parallels: Mapped[str] = mapped_column(default="")
    dv_vinaya_parallels: Mapped[str] = mapped_column(default="")
    dv_others_parallels: Mapped[str] = mapped_column(default="")
    dv_partial_parallels_nā: Mapped[str] = mapped_column(default="")
    dv_partial_parallels_all: Mapped[str] = mapped_column(default="")
    dv_suggested_suttas: Mapped[str] = mapped_column(default="")

    @property
    def sc_card_link(self) -> str | None:
        if self.sc_code:
            return f"https://suttacentral.net/{self.sc_code}"
        else:
            return None

    @property
    def sc_pali_link(self) -> str | None:
        if self.sc_code:
            return f"https://suttacentral.net/{self.sc_code}/pli/ms"
        else:
            return None

    @property
    def sc_eng_link(self) -> str | None:
        if self.sc_code:
            return f"https://suttacentral.net/{self.sc_code}/en/sujato"
        else:
            return None

    @property
    def sc_book_code(self) -> str | None:
        if self.sc_code:
            return re.sub(r"\d+\.*-*\d*", "", self.sc_code)
        else:
            return None

    @property
    def sc_github(self) -> str | None:
        if self.sc_code:
            return (
                f"https://github.com/suttacentral/sc-data/blob/main/{self.sc_file_path}"
            )
        else:
            return None

    @property
    def sc_express_link(self) -> str | None:
        if self.sc_code:
            return f"https://suttacentral.express/{self.sc_code.lower()}/en/sujato"
        else:
            return None

    @property
    def dhamma_gift(self) -> str | None:
        if self.sc_code:
            return f"https://find.dhamma.gift/read/?q={self.sc_code}"
        else:
            return None

    @property
    def tbw(self) -> str | None:
        if self.sc_code:
            if self.book_code in [
                "DN",
                "MN",
                "SN",
                "AN",
                "KHP",
                "DHP",
                "UD",
                "ITI",
                "SNP",
                "TH",
                "THI",
            ]:
                if self.sc_book_code == "iti":
                    return "https://thebuddhaswords.net/it/it.html"
                else:
                    return f"https://thebuddhaswords.net/{self.sc_book_code.lower()}/{self.sc_code.lower()}.html"
            else:
                return None
        else:
            return None

    @property
    def tbw_legacy(self) -> str | None:
        if self.sc_code:
            if self.book_code in [
                "DN",
                "MN",
                "SN",
                "AN",
                "KHP",
                "DHP",
                "UD",
                "ITI",
                "SNP",
                "TH",
                "THI",
            ]:
                if self.sc_book_code == "iti":
                    return "https://find.dhamma.gift/bw/it/it.html"
                else:
                    return f"https://find.dhamma.gift/bw/{self.sc_book_code.lower()}/{self.sc_code.lower()}.html"
            else:
                return None
        else:
            return None

    @property
    def sc_voice_link(self) -> str | None:
        if self.sc_code:
            return f"https://www.sc-voice.net/#/sutta/{self.sc_code.lower()}/en/sujato"
        else:
            return None

    @property
    def tpp_org(self) -> str | None:
        if self.cst_code:
            tpp_org_code = re.sub(r"romn\/|\.xml", "", self.cst_file)
            return (
                f"https://tipitakapali.org/book/{tpp_org_code}#para{self.cst_paranum}"
            )
        else:
            return None

    @property
    def sutta_info_count(self) -> int:
        db_session = object_session(self)
        if db_session is None:
            raise Exception("No db_session")

        return (
            db_session.query(SuttaInfo)
            .filter(
                or_(
                    DpdHeadword.lemma_1 == self.dpd_sutta,
                    DpdHeadword.lemma_1 == self.dpd_sutta_var,
                )
            )
            .count()
        )

    @property
    def sutta_codes_list(self) -> list[str]:
        from tools.sutta_codes import make_list_of_sutta_codes

        return make_list_of_sutta_codes(self)

    @property
    def dv_exists(self) -> bool:
        if (
            self.dv_pts
            or self.dv_main_theme
            or self.dv_subtopic
            or self.dv_stage
            or self.dv_training
            or self.dv_aspect
            or self.dv_teacher
            or self.dv_audience
            or self.dv_method
            or self.dv_length
            or self.dv_prominence
            or self.dv_nikayas_parallels
            or self.dv_āgamas_parallels
            or self.dv_taisho_parallels
            or self.dv_sanskrit_parallels
            or self.dv_vinaya_parallels
            or self.dv_others_parallels
            or self.dv_partial_parallels_nā
            or self.dv_partial_parallels_all
            or self.dv_summary
            or self.dv_key_excerpt1
            or self.dv_key_excerpt2
            or self.dv_similes
            or self.dv_suggested_suttas
        ):
            return True
        else:
            return False

    @property
    def dv_parallels_exists(self) -> bool:
        if (
            self.dv_nikayas_parallels
            or self.dv_āgamas_parallels
            or self.dv_taisho_parallels
            or self.dv_sanskrit_parallels
            or self.dv_vinaya_parallels
            or self.dv_others_parallels
            or self.dv_partial_parallels_nā
            or self.dv_partial_parallels_all
        ):
            return True
        else:
            return False

    def __repr__(self) -> str:
        return f"SuttaInfo: {self.dpd_code} {self.dpd_sutta}"

    @property
    def bjt_github_link(self):
        if self.bjt_filename:
            return f"https://github.com/pathnirvana/tipitaka.lk/blob/master/public/static/text/{self.bjt_filename}.json"
        else:
            return None

    @property
    def bjt_tipitaka_lk_link(self):
        if self.bjt_web_code:
            return f"https://tipitaka.lk/{self.bjt_web_code}"
        else:
            return None

    @property
    def bjt_open_tipitaka_lk_link(self):
        if self.bjt_web_code:
            return f"https://open.tipitaka.lk/latn/{self.bjt_web_code}"
        else:
            return None


class DpdHeadword(Base):
    __tablename__ = "dpd_headwords"

    id: Mapped[int] = mapped_column(primary_key=True)
    lemma_1: Mapped[str] = mapped_column(ForeignKey("sutta_info.dpd_sutta"), default="")
    lemma_2: Mapped[str] = mapped_column(default="")
    pos: Mapped[str] = mapped_column(default="")
    grammar: Mapped[str] = mapped_column(default="")
    derived_from: Mapped[str] = mapped_column(default="")
    neg: Mapped[str] = mapped_column(default="")
    verb: Mapped[str] = mapped_column(default="")
    trans: Mapped[str] = mapped_column(default="")
    plus_case: Mapped[str] = mapped_column(default="")

    meaning_1: Mapped[str] = mapped_column(default="")
    meaning_lit: Mapped[str] = mapped_column(default="")
    meaning_2: Mapped[str] = mapped_column(default="")

    non_ia: Mapped[str] = mapped_column(default="")
    sanskrit: Mapped[str] = mapped_column(default="")

    root_key: Mapped[str] = mapped_column(ForeignKey("dpd_roots.root"), default="")
    root_sign: Mapped[str] = mapped_column(default="")
    root_base: Mapped[str] = mapped_column(default="")

    family_root: Mapped[str] = mapped_column(default="")
    family_word: Mapped[str] = mapped_column(
        ForeignKey("family_word.word_family"), default=""
    )
    family_compound: Mapped[str] = mapped_column(default="")
    family_idioms: Mapped[str] = mapped_column(default="")
    family_set: Mapped[str] = mapped_column(default="")

    construction: Mapped[str] = mapped_column(default="")
    derivative: Mapped[str] = mapped_column(default="")
    suffix: Mapped[str] = mapped_column(default="")
    phonetic: Mapped[str] = mapped_column(default="")
    compound_type: Mapped[str] = mapped_column(default="")
    compound_construction: Mapped[str] = mapped_column(default="")
    non_root_in_comps: Mapped[str] = mapped_column(default="")

    source_1: Mapped[str] = mapped_column(default="")
    sutta_1: Mapped[str] = mapped_column(default="")
    example_1: Mapped[str] = mapped_column(default="")

    source_2: Mapped[str] = mapped_column(default="")
    sutta_2: Mapped[str] = mapped_column(default="")
    example_2: Mapped[str] = mapped_column(default="")

    antonym: Mapped[str] = mapped_column(default="")
    synonym: Mapped[str] = mapped_column(default="")
    variant: Mapped[str] = mapped_column(default="")
    var_phonetic: Mapped[str] = mapped_column(default="")
    var_text: Mapped[str] = mapped_column(default="")
    commentary: Mapped[str] = mapped_column(default="")
    notes: Mapped[str] = mapped_column(default="")
    cognate: Mapped[str] = mapped_column(default="")
    link: Mapped[str] = mapped_column(default="")
    origin: Mapped[str] = mapped_column(default="")

    stem: Mapped[str] = mapped_column(default="")
    pattern: Mapped[str] = mapped_column(
        ForeignKey("inflection_templates.pattern"), default=""
    )

    created_at: Mapped[Optional[DateTime]] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )
    updated_at: Mapped[Optional[DateTime]] = mapped_column(
        DateTime(timezone=True), onupdate=func.now()
    )

    # derived data

    inflections: Mapped[str] = mapped_column(default="")
    inflections_api_ca_eva_iti: Mapped[str] = mapped_column(default="")
    inflections_sinhala: Mapped[str] = mapped_column(default="")
    inflections_devanagari: Mapped[str] = mapped_column(default="")
    inflections_thai: Mapped[str] = mapped_column(default="")
    inflections_html: Mapped[str] = mapped_column(default="")
    freq_data: Mapped[str] = mapped_column(default="")
    freq_html: Mapped[str] = mapped_column(default="")
    ebt_count: Mapped[int] = mapped_column(default=0, server_default="0")

    # pali_root
    rt: Mapped[DpdRoot] = relationship(uselist=False)

    fr = relationship(
        "FamilyRoot",
        primaryjoin=and_(
            root_key == foreign(FamilyRoot.root_key),
            family_root == foreign(FamilyRoot.root_family),
        ),
        uselist=False,
        sync_backref=False,
    )

    #  FamilyWord
    fw = relationship("FamilyWord", uselist=False)

    # inflection templates
    it: Mapped[InflectionTemplates] = relationship()

    # sutta info
    su: Mapped[SuttaInfo] = relationship()

    @hybrid_property
    def root_family_key(self):  # type:ignore
        if self.root_key and self.family_root:
            return f"{self.root_key} {self.family_root}"
        else:
            return ""

    @root_family_key.expression
    def root_family_key(cls):
        return case(
            (
                and_(cls.root_key != null(), cls.family_root != null()),  # type:ignore
                cls.root_key + " " + cls.family_root,
            ),
            else_="",
        )

    @property
    def lemma_1_(self) -> str:
        return self.lemma_1.replace(" ", "_").replace(".", "_")

    @property
    def lemma_link(self) -> str:
        return self.lemma_1.replace(" ", "%20")

    @property
    def lemma_clean(self) -> str:
        return re.sub(r" \d.*$", "", self.lemma_1)

    @property
    def lemma_ipa(self) -> str:
        # from tools.ipa import convert_uni_to_ipa
        # return convert_uni_to_ipa(self.lemma_clean, "ipa")
        from aksharamukha import transliterate

        return str(
            transliterate.process(
                "IASTPali",
                "IPA",
                self.lemma_clean,
            )
        )

    # meaning construction

    @property
    def meaning_combo(self) -> str:
        """`meaning_1` if it exists, else `meaning_2`, plus `literal meaning` if it exists."""
        from tools.meaning_construction import make_meaning_combo

        return make_meaning_combo(self)

    @property
    def meaning_combo_html(self) -> str:
        """`meaning_1` in bold tags if it exists, else `meaning_1`, plus `literal meaning` if it exists."""
        from tools.meaning_construction import make_meaning_combo_html

        return make_meaning_combo_html(self)

    @property
    def root_base_clean(self) -> str:
        from tools.meaning_construction import clean_construction

        return clean_construction(self.root_base)

    @property
    def construction_summary(self) -> str:
        from tools.meaning_construction import summarize_construction

        return summarize_construction(self)

    @property
    def construction_clean(self) -> str:
        from tools.meaning_construction import clean_construction

        return clean_construction(self.construction)

    @property
    def degree_of_completion_html(self) -> str:
        """How complete is a word's information?
        ✔ complete, meaning_1 and example.
        ◑ semi-complete, meaning_1 and no example.
        ✘ incomplete, meaning_2 and no example.
        Styled in gray html tags.
        """
        from tools.degree_of_completion import degree_of_completion

        return degree_of_completion(self)

    @property
    def degree_of_completion(self) -> str:
        """How complete is a word's information?
        ✔ complete, meaning_1 and example.
        ◑ semi-complete, meaning_1 and no example.
        ✘ incomplete, meaning_2 and no example.
        Styled in plain text.
        """
        from tools.degree_of_completion import degree_of_completion

        return degree_of_completion(self, html=False)

    @property
    def lemma_trad(self) -> str:
        from tools.lemma_traditional import make_lemma_trad

        return make_lemma_trad(self)

    @property
    def lemma_trad_clean(self) -> str:
        from tools.lemma_traditional import make_lemma_trad_clean

        return make_lemma_trad_clean(self)

    # root

    @property
    def root_clean(self) -> str:
        try:
            if self.root_key is None:
                return ""
            else:
                return re.sub(r" \d.*$", "", self.root_key)
        except Exception as e:
            print(f"{self.lemma_1}: {e}")
            return ""

    @property
    def construction_line1(self) -> str:
        if self.construction:
            return re.sub("\n.*", "", self.construction)
        else:
            return ""

    @property
    def construction_line1_clean(self) -> str:
        from tools.meaning_construction import clean_construction

        return clean_construction(self.construction_line1)

    @property
    def construction_line1_clean_list(self) -> list[str]:
        return self.construction_line1_clean.split(" + ")

    @property
    def family_compound_list(self) -> list:
        if self.family_compound:
            return self.family_compound.split(" ")
        else:
            return [self.lemma_clean]

    @property
    def family_idioms_list(self) -> list:
        if self.family_idioms:
            return self.family_idioms.split(" ")
        else:
            return [self.lemma_clean]

    @property
    def family_set_list(self) -> list:
        if self.family_set:
            return self.family_set.split("; ")
        else:
            return []

    @property
    def root_count(self) -> int:
        db_session = object_session(self)
        if db_session is None:
            raise Exception("No db_session")

        return (
            db_session.query(DpdHeadword.id)
            .filter(DpdHeadword.root_key == self.root_key)
            .count()
        )

    @property
    def pos_list(self) -> list:
        db_session = object_session(self)
        if db_session is None:
            raise Exception("No db_session")

        pos_db = db_session.query(DpdHeadword.pos).group_by(DpdHeadword.pos).all()
        return sorted([i.pos for i in pos_db])

    @property
    def antonym_list(self) -> list:
        if self.antonym:
            return self.antonym.split(", ")
        else:
            return []

    @property
    def synonym_list(self) -> list:
        if self.synonym:
            return self.synonym.split(", ")
        else:
            return []

    @property
    def variant_list(self) -> list:
        if self.variant:
            return self.variant.split(", ")
        else:
            return []

    @property
    def sanskrit_clean(self) -> str:
        sanskrit_clean = re.sub(r"\[.+\]", "", self.sanskrit)
        return sanskrit_clean.strip()

    # derived data properties

    @property
    def inflections_list(self) -> list[str]:
        if self.inflections:
            return self.inflections.split(",")
        else:
            return []

    @property
    def inflections_list_api_ca_eva_iti(self) -> list[str]:
        if self.inflections_api_ca_eva_iti:
            return self.inflections_api_ca_eva_iti.split(",")
        else:
            return []

    @property
    def inflections_list_all(self) -> list[str]:
        all_inflections = []
        all_inflections.extend(self.inflections.split(","))
        all_inflections.extend(self.inflections_api_ca_eva_iti.split(","))
        return all_inflections

    @property
    def inflections_sinhala_list(self) -> list[str]:
        if self.inflections_sinhala:
            return self.inflections_sinhala.split(",")
        else:
            return []

    @property
    def inflections_devanagari_list(self) -> list[str]:
        if self.inflections_devanagari:
            return self.inflections_devanagari.split(",")
        else:
            return []

    @property
    def inflections_thai_list(self) -> list[str]:
        if self.inflections_thai:
            return self.inflections_thai.split(",")
        else:
            return []

    @property
    def freq_data_unpack(self) -> dict[str, int]:
        if self.freq_data:
            return json.loads(self.freq_data)
        else:
            return {}

    # typst

    @property
    def meaning_1_typst(self) -> str:
        return self.meaning_1.replace("*", r"\*")

    @property
    def meaning_2_typst(self) -> str:
        return self.meaning_2.replace("*", r"\*")

    @property
    def sanskrit_typst(self) -> str:
        return self.sanskrit.replace("[", r"\[").replace("]", r"\]")

    @property
    def root_family_key_typst(self) -> str:
        return self.root_family_key.replace(" ", "_").replace("√", "")

    @property
    def root_base_typst(self) -> str:
        return self.root_base.replace("*", "\\*")

    @property
    def root_sign_typst(self) -> str:
        return self.root_sign.replace("*", "\\*")

    @property
    def construction_typst(self) -> str:
        return self.construction.replace("\n", r"\ ").replace("*", "\\*")

    @property
    def construction_summary_typst(self) -> str:
        from tools.meaning_construction import summarize_construction

        return summarize_construction(self).replace("*", "\\*")

    @property
    def suffix_typst(self) -> str:
        return self.suffix.replace("*", "\\*")

    @property
    def compound_construction_typst(self) -> str:
        return (
            self.compound_construction.replace("*", "\\*")
            .replace("<b>", "#strong[")
            .replace("</b>", "]")
        )

    @property
    def compound_construction_txt(self) -> str:
        return self.compound_construction.replace("<b>", "").replace("</b>", "")

    @property
    def phonetic_typst(self) -> str:
        return self.phonetic.replace("\n", r"\ ")

    @property
    def phonetic_txt(self) -> str:
        return self.phonetic.replace("\n", r", ")

    @property
    def commentary_typst(self) -> str:
        return (
            self.commentary.replace("\n", r"\ ")
            .replace("<b>", "#strong[")
            .replace("</b>", "]")
        )

    @property
    def notes_typst(self) -> str:
        return (
            self.notes.replace("*", r"\*")
            .replace("\n", r"\ ")
            .replace("<b>", "#strong[")
            .replace("</b>", "]")
            .replace("<i>", "_")
            .replace("</i>", "_")
        )

    @property
    def notes_txt(self) -> str:
        notes_clean = (
            self.notes.replace("\n", r" ")
            .replace("<b>", "")
            .replace("</b>", "")
            .replace("<i>", "")
            .replace("</i>", "")
        )
        return re.sub(r"\.$", "", notes_clean)

    @property
    def cognate_typst(self) -> str:
        return self.cognate.replace("*", "\\*")

    @property
    def link_typst(self) -> str:
        link_string: str = ""
        for website in self.link.split("\n"):
            link_string += f"""#link("{website}")\\n"""
        return link_string

    @property
    def link_txt(self) -> str:
        return ", ".join(self.link.split("\n"))

    @property
    def link_list(self) -> list[str]:
        return self.link.split("\n")

    @property
    def example_1_typst(self) -> str:
        return (
            self.example_1.replace("\n", r"\ ")
            .replace("<b>", "#strong[")
            .replace("</b>", "]")
        )

    @property
    def example_2_typst(self) -> str:
        return (
            self.example_2.replace("\n", r"\ ")
            .replace("<b>", "#strong[")
            .replace("</b>", "]")
        )

    @property
    def sutta_1_typst(self) -> str:
        return self.sutta_1.replace("\n", ", ")

    @property
    def sutta_2_typst(self) -> str:
        return self.sutta_2.replace("\n", ", ")

    # needs_button

    @property
    def needs_sutta_info_button(self) -> int:
        from tools.cache_load import load_sutta_info_set

        sutta_info_set = load_sutta_info_set()
        return self.lemma_1 in sutta_info_set

    @property
    def needs_grammar_button(self) -> bool:
        return bool(self.meaning_1)

    @property
    def needs_example_button(self) -> bool:
        return bool(self.meaning_1 and self.example_1 and not self.example_2)

    @property
    def needs_examples_button(self) -> bool:
        return bool(self.meaning_1 and self.example_1 and self.example_2)

    @property
    def needs_conjugation_button(self) -> bool:
        return bool(self.pos in CONJUGATIONS)

    @property
    def needs_declension_button(self) -> bool:
        return bool(self.pos in DECLENSIONS)

    @property
    def needs_root_family_button(self) -> bool:
        return bool(self.family_root)

    @property
    def needs_word_family_button(self) -> bool:
        return bool(self.family_word)

    @property
    def cf_set(self) -> set[str]:
        from tools.cache_load import load_cf_set

        return load_cf_set()

    @property
    def idioms_set(self) -> set[str]:
        from tools.cache_load import load_idioms_set

        return load_idioms_set()

    @property
    def needs_compound_family_button(self) -> bool:
        return bool(
            self.meaning_1
            and " " not in self.family_compound
            and "sandhi" not in self.pos
            and "idiom" not in self.pos
            and "?" not in self.compound_type
            and (
                any(item in self.cf_set for item in self.family_compound_list)
                or (
                    self.lemma_clean in self.cf_set  # type:ignore
                    and not self.family_compound
                )
            )
        )

        # alternative logic
        # i.meaning_1
        # and i.lemma_clean in cf_set)
        # or (
        #     i.meaning_1
        #     and i.family_compound
        #     and any(item in cf_set
        #         for item in i.family_compound_list))

    @property
    def needs_compound_families_button(self) -> bool:
        return bool(
            self.meaning_1
            and " " in self.family_compound
            and "sandhi" not in self.pos
            and "idiom" not in self.pos
            and len(self.lemma_clean) < 30
            and (
                any(item in self.cf_set for item in self.family_compound_list)
                or (
                    self.lemma_clean in self.cf_set  # type:ignore
                    and not self.family_compound
                )
            )
        )

    @property
    def needs_idioms_button(self) -> bool:
        return bool(
            self.meaning_1
            and (
                any(item in self.idioms_set for item in self.family_idioms_list)
                or (not self.family_idioms_list and self.lemma_clean in self.idioms_set)
            )
        )

    @property
    def needs_set_button(self) -> bool:
        return bool(
            self.meaning_1 and self.family_set and len(self.family_set_list) == 1
        )

    @property
    def needs_sets_button(self) -> bool:
        return bool(
            self.meaning_1 and self.family_set and len(self.family_set_list) > 1
        )

    @property
    def needs_frequency_button(self) -> bool:
        return bool(self.pos not in EXCLUDE_FROM_FREQ)

    def __repr__(self) -> str:
        return f"""DpdHeadword: {self.id} {self.lemma_1} {self.pos} {self.meaning_1}"""


class FamilyCompound(Base):
    __tablename__ = "family_compound"
    compound_family: Mapped[str] = mapped_column(primary_key=True)
    html: Mapped[str] = mapped_column(default="")
    data: Mapped[str] = mapped_column(default="")
    count: Mapped[int] = mapped_column(default=0)

    # family_compound pack unpack
    def data_pack(self, list: list[str]) -> None:
        self.data = json.dumps(list, ensure_ascii=False, indent=1)

    @property
    def data_unpack(self) -> list[str]:
        return json.loads(self.data)

    def __repr__(self) -> str:
        return f"FamilyCompound: {self.compound_family} {self.count}"


class FamilyWord(Base):
    __tablename__ = "family_word"
    word_family: Mapped[str] = mapped_column(primary_key=True)
    html: Mapped[str] = mapped_column(default="")
    data: Mapped[str] = mapped_column(default="")
    count: Mapped[int] = mapped_column(default=0)

    dpd_headwords: Mapped[List["DpdHeadword"]] = relationship(
        "DpdHeadword", back_populates="fw"
    )

    # family_word pack unpack
    def data_pack(self, list: list[str]) -> None:
        self.data = json.dumps(list, ensure_ascii=False, indent=1)

    @property
    def data_unpack(self) -> list[str]:
        return json.loads(self.data)

    def __repr__(self) -> str:
        return f"FamilyWord: {self.word_family} {self.count}"


class FamilySet(Base):
    __tablename__ = "family_set"
    set: Mapped[str] = mapped_column(primary_key=True)
    html: Mapped[str] = mapped_column(default="")
    data: Mapped[str] = mapped_column(default="")
    count: Mapped[int] = mapped_column(default=0)

    # family_set pack unpack
    def data_pack(self, list: list[str]) -> None:
        self.data = json.dumps(list, ensure_ascii=False, indent=1)

    @property
    def data_unpack(self) -> list[str]:
        return json.loads(self.data)

    def __repr__(self) -> str:
        return f"FamilySet: {self.set} {self.count}"


class FamilyIdiom(Base):
    __tablename__ = "family_idiom"
    idiom: Mapped[str] = mapped_column(primary_key=True)
    html: Mapped[str] = mapped_column(default="")
    data: Mapped[str] = mapped_column(default="")
    count: Mapped[int] = mapped_column(default=0)

    # idioms data pack unpack
    def data_pack(self, list: list[str]) -> None:
        self.data = json.dumps(list, ensure_ascii=False, indent=1)

    @property
    def data_unpack(self) -> list[str]:
        return json.loads(self.data)

    def __repr__(self) -> str:
        return f"FamilyIdiom: {self.idiom} {self.count}"


class BoldDefinition(Base):
    __tablename__ = "bold_definitions"

    id: Mapped[int] = mapped_column(primary_key=True)
    file_name: Mapped[str] = mapped_column(default="")
    ref_code: Mapped[str] = mapped_column(default="")
    nikaya: Mapped[str] = mapped_column(default="")
    book: Mapped[str] = mapped_column(default="")
    title: Mapped[str] = mapped_column(default="")
    subhead: Mapped[str] = mapped_column(default="")
    bold: Mapped[str] = mapped_column(default="")
    bold_end: Mapped[str] = mapped_column(default="")
    commentary: Mapped[str] = mapped_column(default="")

    def update_bold_definition(
        self,
        file_name,
        ref_code,
        nikaya,
        book,
        title,
        subhead,
        bold,
        bold_end,
        commentary,
    ):
        self.file_name = file_name
        self.ref_code = ref_code
        self.nikaya = nikaya
        self.book = book
        self.title = title
        self.subhead = subhead
        self.bold = bold
        self.bold_end = bold_end
        self.commentary = commentary

    def __repr__(self) -> str:
        return f"""
{"file_name":<20}{self.file_name}
{"ref_code":<20}{self.ref_code}
{"nikaya":<20}{self.nikaya}
{"book":<20}{self.book}
{"title":<20}{self.title}
{"subhead":<20}{self.subhead}
{"bold":<20}{self.bold}
{"bold_end":<20}{self.bold_end}
{"commentary":<20}{self.commentary}
"""

</file>


<file path="exporter/goldendict/export_roots.py">
"""Compile HTML data for Roots dictionary."""

import re
from typing import Dict, List, Tuple

from mako.template import Template
from minify_html import minify
from sqlalchemy.orm import Session

from db.models import DpdRoot, FamilyRoot
from exporter.goldendict.helpers import TODAY
from tools.css_manager import CSSManager
from tools.goldendict_exporter import DictEntry
from tools.niggahitas import add_niggahitas
from tools.pali_sort_key import pali_sort_key
from tools.paths import ProjectPaths
from tools.printer import printer as pr
from tools.utils import RenderedSizes, default_rendered_sizes, squash_whitespaces


def generate_root_html(
    db_session: Session,
    pth: ProjectPaths,
    roots_count_dict: Dict[str, int],
) -> Tuple[List[DictEntry], RenderedSizes]:
    """compile html components for each pali root"""

    pr.green("generating roots html")
    size_dict = default_rendered_sizes()
    root_data_list: List[DictEntry] = []

    header_templ = Template(filename=str(pth.root_header_templ_path))

    roots_db = db_session.query(DpdRoot).all()

    for counter, r in enumerate(roots_db):
        # replace \n with html line break
        if r.panini_root:
            r.panini_root = r.panini_root.replace("\n", "<br>")
        if r.panini_sanskrit:
            r.panini_sanskrit = r.panini_sanskrit.replace("\n", "<br>")
        if r.panini_english:
            r.panini_english = r.panini_english.replace("\n", "<br>")

        html = ""
        html += "<body>"

        root_header = render_root_header_templ(
            pth, r=r, date=str(TODAY), header_templ=header_templ
        )

        # Add variables and fonts
        css_manager = CSSManager()
        root_header = css_manager.update_style(root_header, "root")

        definition = render_root_definition_templ(
            pth,
            r,
            roots_count_dict,
        )
        html += definition
        size_dict["root_definition"] += len(definition)

        root_buttons = render_root_buttons_templ(
            pth,
            r,
            db_session,
        )
        html += root_buttons
        size_dict["root_buttons"] += len(root_buttons)

        root_info = render_root_info_templ(
            pth,
            r,
        )
        html += root_info
        size_dict["root_info"] += len(root_info)

        root_matrix = render_root_matrix_templ(
            pth,
            r,
            roots_count_dict,
        )
        html += root_matrix
        size_dict["root_matrix"] += len(root_matrix)

        root_families = render_root_families_templ(
            pth,
            r,
            db_session,
        )
        html += root_families
        size_dict["root_families"] += len(root_families)

        html += "</body></html>"

        html = squash_whitespaces(root_header) + minify(html)

        synonyms: set = set()
        synonyms.add(r.root_clean)
        synonyms.add(re.sub("√", "", r.root))
        synonyms.add(re.sub("√", "", r.root_clean))

        frs = db_session.query(FamilyRoot).filter(FamilyRoot.root_key == r.root).all()

        for fr in frs:
            synonyms.add(fr.root_family)
            synonyms.add(re.sub("√", "", fr.root_family))

        synonyms = set(add_niggahitas(list(synonyms)))
        size_dict["root_synonyms"] += len(str(synonyms))

        res = DictEntry(
            word=r.root,
            definition_html=html,
            definition_plain="",
            synonyms=list(synonyms),
        )

        root_data_list.append(res)

    pr.yes(len(root_data_list))
    return root_data_list, size_dict


def render_root_header_templ(
    __pth__: ProjectPaths, r: DpdRoot, date: str, header_templ: Template
) -> str:
    """render the html header with variables"""

    return str(header_templ.render(r=r, date=date))


def render_root_definition_templ(
    pth: ProjectPaths,
    r: DpdRoot,
    roots_count_dict,
):
    """render html of main root info"""

    root_definition_templ = Template(filename=str(pth.root_definition_templ_path))

    try:
        count = roots_count_dict[r.root]
    except KeyError:
        count = 0

    return str(
        root_definition_templ.render(
            r=r,
            count=count,
            today=TODAY,
        )
    )


def render_root_buttons_templ(
    pth: ProjectPaths,
    r: DpdRoot,
    db_session: Session,
):
    """render html of root buttons"""

    root_buttons_templ = Template(filename=str(pth.root_button_templ_path))

    frs = db_session.query(FamilyRoot).filter(FamilyRoot.root_key == r.root)

    frs = sorted(frs, key=lambda x: pali_sort_key(x.root_family))

    return str(root_buttons_templ.render(r=r, frs=frs))


def render_root_info_templ(pth: ProjectPaths, r: DpdRoot):
    """render html of root grammatical info"""

    root_info_templ = Template(filename=str(pth.root_info_templ_path))
    root_info = ""

    return str(root_info_templ.render(r=r, root_info=root_info, today=TODAY))


def render_root_matrix_templ(
    pth: ProjectPaths,
    r: DpdRoot,
    roots_count_dict,
):
    """render html of root matrix"""

    root_matrix_templ = Template(filename=str(pth.root_matrix_templ_path))
    root_matrix = ""

    try:
        count = roots_count_dict[r.root]
    except KeyError:
        count = 0

    return str(
        root_matrix_templ.render(r=r, count=count, root_matrix=root_matrix, today=TODAY)
    )


def render_root_families_templ(
    pth: ProjectPaths,
    r: DpdRoot,
    db_session: Session,
):
    """render html of root families"""

    root_families_templ = Template(filename=str(pth.root_families_templ_path))

    frs = (
        db_session.query(FamilyRoot)
        .filter(
            FamilyRoot.root_key == r.root,
        )
        .all()
    )

    frs = sorted(frs, key=lambda x: pali_sort_key(x.root_family))

    return str(root_families_templ.render(r=r, frs=frs, today=TODAY))

</file>


<file path="exporter/goldendict/helpers.py">
"""A few helpful lists and functions for the exporter."""

from typing import Dict
from datetime import date

from sqlalchemy.orm import Session

from db.models import DpdHeadword

TODAY = date.today()

EXCLUDE_FROM_SETS: set = {"dps", "ncped", "pass1", "sandhi"}


def make_roots_count_dict(db_session: Session) -> Dict[str, int]:
    roots_db = db_session.query(DpdHeadword).all()
    roots_count_dict: Dict[str, int] = dict()
    for i in roots_db:
        if i.root_key is None:
            continue
        if i.root_key in roots_count_dict:
            roots_count_dict[i.root_key] += 1
        else:
            roots_count_dict[i.root_key] = 1

    return roots_count_dict

</file>


<file path="tools/cache_load.py">
#!/usr/bin/env python3

"""Get cf_set and idioms_set from the DbInfo cache."""

import json

from db.db_helpers import get_db_session
from tools.paths import ProjectPaths

pth = ProjectPaths()
db_session = get_db_session(pth.dpd_db_path)

_cf_set_cache = None
_idioms_set_cache = None
_sutta_info_cache = None


def load_sutta_info_set():
    from db.models import SuttaInfo

    global _sutta_info_cache

    if _sutta_info_cache is not None:
        return _sutta_info_cache
    else:
        db = (
            db_session.query(SuttaInfo.dpd_sutta, SuttaInfo.dpd_sutta_var)
            .filter(SuttaInfo.dpd_code != "")
            .all()
        )
        _sutta_info_cache = set([i[0] for i in db])
        # _sutta_info_cache.update([i[1] for i in db if i[1]]) exclude for now
        return _sutta_info_cache


def load_cf_set() -> set[str]:
    """generate a list of all compounds families"""
    from db.models import DbInfo

    global _cf_set_cache

    if _cf_set_cache is not None:
        return _cf_set_cache
    else:
        cf_set_cache = db_session.query(DbInfo).filter_by(key="cf_set").first()
        cf_set = json.loads(cf_set_cache.value)
        _cf_set_cache = cf_set
        return cf_set


def load_idioms_set() -> set[str]:
    """generate a list of all compounds families"""
    from db.models import DbInfo

    global _idioms_set_cache

    if _idioms_set_cache is not None:
        return _idioms_set_cache
    else:
        idioms_set_cache = db_session.query(DbInfo).filter_by(key="idioms_set").first()
        idioms_set = json.loads(idioms_set_cache.value)
        _idioms_set_cache = idioms_set
        return idioms_set


if __name__ == "__main__":
    from db.models import DbInfo

    print(load_cf_set(DbInfo))


# --------------------------------------old-----------------
# pth = ProjectPaths()

# _cached_cf_set: Optional[Set[str]] = None

# def cf_set_gen() -> Set[str]:
#     """generate a list of all compounds families"""
#     global _cached_cf_set

#     if _cached_cf_set is not None:
#         return _cached_cf_set

#     db_session = get_db_session(pth.dpd_db_path)
#     cf_db = db_session.query(FamilyCompound).all()

#     cf_set: Set[str] = set()
#     for i in cf_db:
#         cf_set.add(i.compound_family)

#     _cached_cf_set = cf_set
#     return cf_set

</file>


<file path="tools/configger.py">
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""Modules for initializing, reading, writing, updating and testing
config.ini file."""

import configparser
from typing import Optional

from tools.printer import printer as pr

config = configparser.ConfigParser()
config.read("config.ini")

DEFAULT_CONFIG = {
    "version": {
        "version": "",
    },
    "regenerate": {
        "inflections": "yes",
        "transliterations": "yes",
        "freq_maps": "yes",
        "db_rebuild": "no",
    },
    "deconstructor": {
        "use_premade": "no",
    },
    "gui": {
        "theme": "DarkGrey10",
        "screen_fraction_width": "0.60",
        "screen_fraction_height": "1",
        "window_x": "0",
        "window_y": "0",
        "font_name": "Noto Sans",
        "font_size": "14",
        "input_text_color": "darkgray",
        "text_color": "#00bfff",
        "element_padding_x": "0",
        "element_padding_y": "0",
        "margin_x": "0",
        "margin_y": "0",
    },
    "goldendict": {"copy_unzip": "no", "path": ""},
    "dictionary": {
        "make_mdict": "yes",
        "show_id": "no",
        "data_limit": "0",
    },
    "exporter": {
        "make_dpd": "yes",
        "make_deconstructor": "no",
        "make_grammar": "no",
        "make_variants": "no",
        "make_tpr": "no",
        "make_ebook": "no",
        "make_tbw": "no",
        "make_pdf": "no",
        "make_abbrev": "no",
        "tarball_db": "no",
        "make_changelog": "no",
        "update_simsapa_db": "no",
    },
    "apis": {"openai": "", "deepseek": "", "gemini": "", "openrouter": ""},
    "anki": {"update": "no", "db_path": "", "backup_path": ""},
    "simsapa": {"app_path": "", "db_path": ""},
    "tpr": {"db_path": ""},
}


def config_initialize() -> None:
    """Initialize config.ini with default values."""
    for section, options in DEFAULT_CONFIG.items():
        if not config.has_section(section):
            config.add_section(section)
        for option, value in options.items():
            if not config.has_option(section, option):
                config.set(section, option, value)
    config_write()


def config_read(
    section: str, option: str, default_value: Optional[str] = None
) -> str | None:
    """Read config.ini. If error, return a specified default value"""
    try:
        return config.get(section, option)
    except (configparser.NoSectionError, configparser.NoOptionError):
        return default_value


def config_write() -> None:
    """Write config.ini."""
    with open("config.ini", "w") as file:
        config.write(file)


def config_update(section: str, option: str, value, silent=False) -> None:
    """Update config.ini with a new section, option & value."""
    if config.has_section(section):
        config.set(section, option, str(value))
    else:
        config.add_section(section)
        config.set(section, option, str(value))
    config_write()
    if not silent:
        pr.green_title(f"config updated: {section}: {option} --> {value}")


def config_test(section: str, option: str, value) -> bool:
    """Test config.ini to see if a section, option equals a value."""
    if config.has_section(section) and config.has_option(section, option):
        return config.get(section, option) == str(value)
    else:
        pr.red(f"unknown config setting: {section}: {option}")
        config_update_default_value(section, option)
        return config.get(section, option, fallback="") == str(value)


def config_update_default_value(section: str, option: str) -> None:
    """Update config.ini with a default value for a missing section or option."""
    if section in DEFAULT_CONFIG and option in DEFAULT_CONFIG[section]:
        default_value = DEFAULT_CONFIG[section].get(option)
        config_update(section, option, default_value)
    else:
        pr.red(f"missing default value for {section}: {option}")


def config_test_section(section):
    """Test config.ini to see if a section exists."""
    if config.has_section(section):
        return True
    else:
        return False


def config_test_option(section, option):
    """Test config.ini to see if a section, option exists."""
    if config.has_section(section):
        return config.has_option(section, option)
    else:
        return False


def print_config_settings(sections_to_print=None) -> None:
    """Print specified sections from config.ini or all if not specified."""
    if sections_to_print is None:
        sections_to_print = config.sections()
    for section in sections_to_print:
        if config.has_section(section):
            pr.info(f"[{section}]")
            for key, value in config.items(section):
                pr.info(f"{key} = {value}")


if __name__ == "__main__":
    config_initialize()

</file>


<file path="tools/css_manager.py">
# -*- coding: utf-8 -*-
"""
1. Create a Single Source of Truth for all CSS files.
    1. WebApp
    2. All GoldenDict exporters
    3. MkDocs

2. Dynamically update the headers of all exported dictionary with the correct variables.
"""

import re

from tools.paths import ProjectPaths


class CSSManager:
    def __init__(self):
        self.pth: ProjectPaths = ProjectPaths()
        self.dpd_css: str = self.pth.dpd_css_path.read_text()
        self.dpd_variables: str = self.pth.dpd_variables_css_path.read_text()
        self.dpd_fonts: str = self.pth.dpd_fonts_css_path.read_text()
        self.variables_reduced = self.dpd_variables

    def update_webapp_css(self) -> None:
        """The WebApp needs variables and dpd.css. No fonts in the CSS."""

        css_list: list[str] = []
        css_list.append(self.dpd_variables)
        css_list.append("")
        css_list.append(self.dpd_css)

        css_file = "\n".join(css_list)
        self.pth.webapp_css_path.write_text(css_file)

    def update_docs_css(self):
        """Save the CSS Variables to the docs folder."""

        self.pth.docs_css_variables_path.write_text(self.dpd_variables)

    def compile_css_and_fonts(self):
        """Compile CSS and fonts into one for GoldenDict exporters."""

        css_and_fonts_list = []
        css_and_fonts_list.append(self.dpd_fonts)
        css_and_fonts_list.append("")
        css_and_fonts_list.append(self.dpd_css)
        css_and_fonts_str = "\n".join(css_and_fonts_list)
        self.pth.dpd_css_and_fonts_path.write_text(css_and_fonts_str)

    def update_style(self, header: str, used_for: str):
        """
        Replace the style in exporter headers with fonts and variables.

        `used_for` values can be
        - `primary`: grammar_dict, spelling, epd
        - `secondary`: help and abbreviations
        - `dpd`: main dict
        - `root`: root dict
        - `variants`: variant dict
        """

        self.reduce_style(used_for)
        self.new_style = f"""
<style>
{self.variables_reduced}
"""
        # print(self.new_style)
        return header.replace("<style>", self.new_style)

    def reduce_style(self, used_for):
        """Based on `used_for`, strip away unnecessary variables"""

        if used_for == "primary":
            self._remove_all_except(["--primary"])
        if used_for == "secondary":
            self._remove_all_except(["--secondary"])
        if used_for == "dpd":
            self._remove_comments_and_whitespace()
            self._remove_only(["shade"])
        if used_for == "root":
            self._remove_all_except(["--primary", "--gray"])
        if used_for == "variants":
            self._remove_all_except(["--primary", "--gray"])
            self._remove_only(["--gray-light", "--gray-dark"])

    def _remove_all_except(self, variables: list[str]):
        """Remove all variables except the ones in the list."""

        lines = self.variables_reduced.splitlines()
        # leave lines with {} and the necessary variable
        lines = [
            line
            for line in lines
            if any(variable in line for variable in variables)
            or ("{" in line or "}" in line)
        ]
        self.variables_reduced = "\n".join(lines)

    def _remove_only(self, variables: list[str]):
        """Only remove the variables in the list."""

        lines = self.variables_reduced.splitlines()
        for variable in variables:
            # leave lines with {} and without necessary variable
            lines = [
                line
                for line in lines
                if variable not in line or ("{" in line or "}" in line)
            ]
        self.variables_reduced = "\n".join(lines)

    def _remove_comments_and_whitespace(self):
        "Strip away comments and empty lines."

        self.variables_reduced = re.sub(r"/\*[\s\S]*?\*/", "", self.variables_reduced)
        lines = self.variables_reduced.splitlines()
        lines = [line for line in lines if line.strip()]
        self.variables_reduced = "\n".join(lines)


if __name__ == "__main__":
    css_manager = CSSManager()
    css_manager.update_docs_css()
    css_manager.update_webapp_css()
    css_manager.compile_css_and_fonts()
    # new_style = css_manager.update_style("<style>", "secondary")
    # print(new_style)

</file>


<file path="tools/date_and_time.py">
"""Get basic day, date, time info."""

from datetime import datetime

now = datetime.now()


def year_month_day_hour_minute_dash():
    return now.strftime("%Y-%m-%d-%H-%M")


def year_month_day_dash():
    return now.strftime("%Y-%m-%d")


def year_month_day():
    return now.strftime("%Y%m%d")


def hour_minute():
    return now.strftime("%H:%M")


def day():
    return now.strftime("%d")


def make_timestamp() -> str:
    """Make current time iso-formatted UTC datetime string"""
    now = datetime.utcnow().replace(microsecond=0)
    return now.isoformat()

</file>


<file path="tools/degree_of_completion.py">
from db.models import DpdHeadword


def degree_of_completion(i: DpdHeadword, html=True):
    """
    Return plain or HTML styled symbol of a word data degree of completion.
    ✔ = complete = meaning_1 and source_1
    ◑ = half-complete = meaning_1 and no source_1
    ✘ = incomplete = no meaning_1
    """

    if i.meaning_1:
        if i.source_1:
            if html:
                return """<span class="gray">✔</span>"""
            else:
                return "✔"

        else:
            if html:
                return """<span class="gray">◑</span>"""
            else:
                return "◑"
    else:
        if html:
            return """<span class="gray">✘</span>"""
        else:
            return "✘"

</file>


<file path="tools/goldendict_exporter.py">
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""Generic GoldenDict exporter using pyglossary."""

import os
import shutil
from pathlib import Path
from subprocess import Popen
from typing import Optional
from zipfile import ZIP_DEFLATED, ZipFile

import idzip
from pyglossary import Glossary

from tools.date_and_time import make_timestamp
from tools.goldendict_path import make_goldendict_path
from tools.printer import printer as pr


class DictEntry:
    """Data for a single dictionary entry"""

    def __init__(self, word, definition_html, definition_plain, synonyms) -> None:
        self.word: str = word
        self.definition_html: str = definition_html
        self.definition_plain: str = definition_plain
        self.synonyms: list[str] = synonyms


class DictInfo:
    """Dictionary Information"""

    def __init__(
        self, bookname, author, description, website, source_lang, target_lang
    ) -> None:
        self.bookname: str = bookname
        self.author: str = author
        self.description: str = description
        self.website: str = website
        self.source_lang: str = source_lang
        self.target_lang: str = target_lang
        self.date = make_timestamp()


class DictVariables:
    """All relevant dictionary variables.
    Usage:
    dict_vars = DictVariables(
        css_path = css_path,
        js_paths = js_paths,
        gd_path = gd_path,
        md_path = md_path,
        dict_name = dict_name,
        icon_path = None,
        font_path = None
        zip_up = False,
        delete_original = False,
    """

    def __init__(
        self,
        css_paths: Optional[list[Path]],
        js_paths: Optional[list[Path]],
        gd_path: Path,
        md_path: Path,
        dict_name: str,
        icon_path: Optional[Path],
        font_path: Optional[Path] = None,
        zip_up: bool = False,
        delete_original: bool = False,
    ) -> None:
        self.css_paths: Optional[list[Path]] = css_paths
        self.js_paths: Optional[list[Path]] = js_paths

        self.gd_path: Path = gd_path.joinpath(dict_name)
        self.gd_name_name: Path = Path(dict_name).with_suffix(".ifo")
        self.gd_path_name: Path = self.gd_path.joinpath(dict_name).with_suffix(".ifo")

        self.dictfile = self.gd_path_name.with_suffix(".dict")
        self.dictfile_zip = self.gd_path_name.with_suffix(".dict.dz")

        self.synfile: Path = self.gd_path_name.with_suffix(".syn")
        self.synfile_zip: Path = self.synfile.with_suffix(".syn.dz")

        self.slob_path_name: Path = gd_path.joinpath(dict_name).with_suffix(".slob")

        self.mdict_mdx_path: Path = md_path.joinpath(f"{dict_name}-mdict").with_suffix(
            ".mdx"
        )
        self.mdict_mdd_path: Path = md_path.joinpath(f"{dict_name}-mdict").with_suffix(
            ".mdd"
        )
        self.icon_source_path: Optional[Path] = icon_path

        if icon_path:
            self.icon_target_path = self.gd_path_name.with_suffix(".ico")

        self.font_source_path = font_path
        if self.font_source_path:
            self.font_target_dir = self.gd_path_name

        if zip_up:
            self.zip_up = zip_up
        else:
            self.zip_up = False

        if delete_original:
            self.delete_original = delete_original
        else:
            self.delete_original = False

        if gd_path.samefile(md_path):
            self.gd_zip_path = gd_path.joinpath(f"{dict_name}-goldendict").with_suffix(
                ".zip"
            )
            self.md_zip_path = md_path.joinpath(f"{dict_name}-mdict").with_suffix(
                ".zip"
            )
        else:
            self.gd_zip_path = gd_path.joinpath(dict_name).with_suffix(".zip")
            self.md_zip_path = md_path.joinpath(dict_name).with_suffix(".zip")


def delete_old_directory(dict_var: DictVariables) -> bool:
    """Delete old dictionary directory if it exists."""
    pr.white("deleting old directory")
    if dict_var.gd_path.exists():
        try:
            shutil.rmtree(dict_var.gd_path)
            pr.yes("ok")
            return True
        except Exception as e:
            pr.no("error")
            pr.red(str(e))
            return False
    else:
        pr.yes("no")
        return True


def create_glossary(dict_info: DictInfo) -> Glossary:
    """Create Glossary."""

    pr.white("creating glossary")
    Glossary.init()
    glos = Glossary(
        info={
            "bookname": dict_info.bookname,
            "author": dict_info.author,
            "description": dict_info.description,
            "website": dict_info.website,
            "sourceLang": dict_info.source_lang,
            "targetLang": dict_info.target_lang,
            "date": dict_info.date,
        }
    )

    pr.yes("ok")
    return glos


def add_css(glos: Glossary, dict_var: DictVariables) -> Glossary:
    """Add CSS file."""

    pr.white("adding css")
    if dict_var.css_paths:
        for css_path in dict_var.css_paths:
            if css_path and css_path.exists():
                css = css_path.read_bytes()
                glos.addEntry(glos.newDataEntry(css_path.name, css))
        pr.yes("ok")
    else:
        pr.yes("no")
    return glos


def add_js(glos: Glossary, dict_var: DictVariables) -> Glossary:
    """Add JS file."""

    pr.white("adding js")
    if dict_var.js_paths:
        for js_path in dict_var.js_paths:
            if js_path and js_path.exists():
                js = js_path.read_bytes()
                glos.addEntry(glos.newDataEntry(js_path.name, js))
        pr.yes("ok")
    else:
        pr.yes("no")

    return glos


def add_fonts(glos: Glossary, dict_var: DictVariables) -> Glossary:
    """Add the fonts."""

    pr.white("adding fonts")
    if dict_var.font_source_path:
        for font_path in dict_var.font_source_path.iterdir():
            # Check if the file exists and has a valid font extension
            if (
                font_path
                and font_path.exists()
                and font_path.suffix.lower() in [".ttf", ".otf"]  # <-- Added check
            ):
                font_file = font_path.read_bytes()
                glos.addEntry(glos.newDataEntry(font_path.name, font_file))
        pr.yes("ok")
    else:
        pr.yes("no")

    return glos


def add_data(glos: Glossary, dict_data: list[DictEntry]) -> Glossary:
    """Add dictionary data to glossary."""

    pr.white("compiling data")
    for d in dict_data:
        glos.addEntry(
            glos.newEntry(
                word=[d.word] + d.synonyms, defi=d.definition_html, defiFormat="h"
            )  # type:ignore
        )

    pr.yes("ok")
    return glos


def write_to_file(glos: Glossary, dict_var: DictVariables) -> None:
    """Write output files."""

    pr.white("writing goldendict file")
    glos.write(
        filename=str(dict_var.gd_path_name),
        format="Stardict",
        # dictzip=True,
        dictzip=False,
        sametypesequence="h",
        sqlite=True,  # when False, more RAM but faster
    )
    pr.yes("ok")


def zip_dictfile(dict_var: DictVariables) -> None:
    """Compress .dict file into dictzip format using idzip."""

    pr.white("zipping .dict")

    try:
        with (
            open(dict_var.dictfile, "rb") as input_f,
            open(dict_var.dictfile_zip, "wb") as output_f,
        ):
            input_info = os.fstat(input_f.fileno())
            idzip.compressor.compress(  # type:ignore
                input_f,
                input_info.st_size,
                output_f,
                dict_var.dictfile.name,
                int(input_info.st_mtime),
            )
            dict_var.dictfile.unlink()
            pr.yes("ok")
    except FileNotFoundError:
        pr.no(f"error, {dict_var.dictfile} not found")


def zip_synfile(dict_var: DictVariables) -> None:
    """Compress .syn file into dictzip format"""

    pr.white("zipping synonyms")
    try:
        with (
            open(dict_var.synfile, "rb") as input_f,
            open(dict_var.synfile_zip, "wb") as output_f,
        ):
            input_info = os.fstat(input_f.fileno())
            idzip.compressor.compress(  # type:ignore
                input_f,
                input_info.st_size,
                output_f,
                dict_var.synfile.name,
                int(input_info.st_mtime),
            )
            dict_var.synfile.unlink()
            pr.yes("ok")
    except FileNotFoundError:
        pr.yes("no")
    except Exception:
        pr.no(f"error, {dict_var.synfile} not found")


def add_icon(v: DictVariables) -> None:
    """Copy the icon if provided."""

    pr.white("copying icon")
    if v.icon_source_path is not None:
        if v.icon_source_path.exists():
            try:
                Popen(["cp", v.icon_source_path, v.icon_target_path])
                pr.yes("ok")
            except Exception:
                pr.no("error")
    else:
        pr.yes("no")


def copy_dir(v: DictVariables) -> None:
    """Copy to Goldendict dir, cleaning up the destination first."""

    pr.white("copying to GoldenDict dir")
    goldendict_pth: Path | str = make_goldendict_path()
    if goldendict_pth:
        if goldendict_pth.exists():
            target_dir = goldendict_pth.joinpath(v.gd_path.name)

            # Delete old version in GoldenDict dir if it exists
            if target_dir.exists():
                try:
                    shutil.rmtree(target_dir)
                    # pr.yes("ok")
                except Exception as e:
                    pr.no("error")
                    pr.red(str(e))

            # Copy new version
            try:
                shutil.copytree(v.gd_path, target_dir)
                pr.yes("ok")
            except Exception as e:
                pr.no("error")
                pr.red(str(e))
    else:
        pr.yes("no goldendict path found")


def zip_folder(dict_var: DictVariables):
    """Zip up the gd and md files."""

    pr.white("zipping directory")
    with ZipFile(dict_var.gd_zip_path, "w", ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(dict_var.gd_path):
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, dict_var.gd_path)
                zipf.write(file_path, relative_path)
    pr.yes("ok")


def delete_original(dict_var: DictVariables):
    """Delete the original output folder"""

    pr.white("deleting folder")
    try:
        shutil.rmtree(dict_var.gd_path)
        pr.yes("ok")
    except Exception as e:
        pr.no("error")
        pr.red(str(e))


def write_to_slob(glos: Glossary, dict_var: DictVariables) -> None:
    """Write to slob format files."""

    pr.white("writing slob file")
    glos.write(
        filename=str(dict_var.slob_path_name),
        format="Aard2Slob",
        compression="",  # "", "bz2", "zlib", "lzma2"
        content_type="text/html; charset=utf-8",
        word_title=True,
    )
    pr.yes("ok")


def export_to_goldendict_with_pyglossary(
    dict_info: DictInfo,
    dict_var: DictVariables,
    dict_data: list[DictEntry],
    include_slob=False,
) -> None:
    """Usage:
    export_to_goldendict_with_pyglossary(
        dict_info,
        dict_var,
        dict_data,
        include_slob = False,
    )
    """

    pr.green_title("exporting to goldendict with pyglossary")

    if not delete_old_directory(dict_var):
        return

    glos = create_glossary(dict_info)
    glos = add_css(glos, dict_var)
    glos = add_js(glos, dict_var)
    glos = add_fonts(glos, dict_var)
    glos = add_data(glos, dict_data)

    write_to_file(glos, dict_var)
    zip_dictfile(dict_var)
    zip_synfile(dict_var)
    add_icon(dict_var)
    copy_dir(dict_var)

    if dict_var.zip_up:
        zip_folder(dict_var)

    if dict_var.delete_original:
        delete_original(dict_var)

    if include_slob:
        write_to_slob(glos, dict_var)

</file>


<file path="tools/goldendict_path.py">
from pathlib import Path
from rich import print
from rich.prompt import Prompt


from tools.configger import config_test, config_test_option, config_update, config_read


def make_goldendict_path() -> Path:
    """Add a Goldendict path if one doesn't exist,
    or return the path if it does."""

    if config_test("goldendict", "copy_unzip", "yes"):
        if not config_test_option("goldendict", "path"):
            goldendict_path = Prompt.ask(
                "[yellow]Enter your GoldenDict directory (or ENTER for None)"
            )
            config_update("goldendict", "path", goldendict_path)
            return Path(goldendict_path)
        else:
            return Path(config_read("goldendict", "path"))


if __name__ == "__main__":
    print(Path(make_goldendict_path()))

</file>


<file path="tools/lemma_traditional.py">
#!/usr/bin/env python3

"""Function to provide traditional lemma endings."""

import re

from db.models import DpdHeadword
from tools.sinhala_tools import translit_ro_to_si

lemma_trad_dict: dict[str, str] = {
    "ant adj": "antu",  # like sīlavant
    "ant masc": "antu",  # like bhagavant
    "ar fem": "u",  # like dhītar
    "ar masc": "u",  # like satthar
    "ar2 masc": "u",  # like pitar
    "arahant masc": "arahanta",  # like arahant
    "as masc": "a",  # like manas
    "bhavant masc": "bhavantu",  # like bhavant
    "mātar fem": "mātu",  # like mātar
}


def find_space_digits(i: DpdHeadword) -> str:
    pattern = r"\s\d.*"
    match = re.search(pattern, i.lemma_1)
    if match:
        return match.group()
    else:
        return ""


def make_lemma_trad_clean(i: DpdHeadword) -> str:
    """Return a traditional noun or adj ending, rather than the DPD ending."""

    if (
        "!" not in i.stem  # only process lemmas, not inflected forms
        and i.pattern in lemma_trad_dict
    ):
        ending = lemma_trad_dict[i.pattern]
        lemma_trad_clean = f"{i.stem}{ending}".replace("!", "").replace("*", "")
        return lemma_trad_clean
    else:
        return i.lemma_clean


def make_lemma_trad(i: DpdHeadword) -> str:
    """Return a traditional noun or adj ending, rather than the DPD ending.
    no trailing number"""

    if (
        # only process lemmas, not inflected forms
        "!" not in i.stem and i.pattern in lemma_trad_dict
    ):
        space_digits = find_space_digits(i)
        ending = lemma_trad_dict[i.pattern]
        lemma_trad = f"{i.stem}{ending}{space_digits}".replace("!", "").replace("*", "")
        # print(f"{i.lemma_1:<40}{lemma_trad}")
        return lemma_trad
    else:
        return i.lemma_1


def make_lemma_trad_si(i: DpdHeadword) -> str:
    """Transcribe traditional lemma into Sinhala."""
    lemma = make_lemma_trad(i)
    return translit_ro_to_si(lemma)

</file>


<file path="tools/meaning_construction.py">
"""Functions for:
1. Summarizing meaning and literal meaning,
2. Summarizing construction,
3. Cleaning construction of all brackets and phonetic changes,
4. Creating an HTML styled symbol of a word data's degree of completion."""

from pathlib import Path
import re

from db.db_helpers import get_db_session
from db.models import DpdHeadword


def make_meaning_combo(i: DpdHeadword) -> str:
    """Compile meaning_1 and literal meaning, or return meaning_2."""
    if i.meaning_1:
        meaning: str = i.meaning_1
        if i.meaning_lit:
            meaning += f"; lit. {i.meaning_lit}"
        return meaning
    elif i.meaning_2:
        return i.meaning_2
    else:
        return ""


def make_meaning_combo_html(i: DpdHeadword) -> str:
    """Compile meaning_1 in bold tags and meaning_lit,
    or return meaning_2 and meaning_lit."""

    if i.meaning_1:
        meaning: str = f"<b>{i.meaning_1}</b>"
        if i.meaning_lit:
            meaning += f"; lit. {i.meaning_lit}"
        return meaning
    else:
        if "; lit." in i.meaning_2:
            return i.meaning_2
        elif i.meaning_lit:
            return f"{i.meaning_2}; lit. {i.meaning_lit}"
        else:
            return i.meaning_2


def make_grammar_line(i: DpdHeadword) -> str:
    """Compile grammar line"""

    grammar = i.grammar
    if i.neg:
        grammar += f", {i.neg}"
    if i.verb:
        grammar += f", {i.verb}"
    if i.trans:
        grammar += f", {i.trans}"
    if i.plus_case:
        grammar += f" ({i.plus_case})"
    return grammar


def summarize_construction(i: DpdHeadword) -> str:
    """Create a summary of a word's construction,
    excluding brackets and phonetic changes."""

    if "<b>" in i.construction:
        i.construction = i.construction.replace("<b>", "").replace("</b>", "")

    # if no meaning then show root, word family or nothing
    if not i.meaning_1 and i.origin not in ["pass1", "pass2"]:
        if i.root_key:
            return i.family_root.replace(" ", " + ")
        elif i.family_word:
            return i.family_word
        else:
            return ""

    elif i.meaning_1 or (not i.meaning_1 and i.origin in ["pass1", "pass2"]):
        if not i.construction:
            return ""

        # clean construction
        # remove line2
        construction = re.sub(r"\n.+$", "", i.construction)
        # remove phonetic changes
        construction = re.sub("> .[^ ]*? ", "", construction)
        # remove phonetic changes at end
        construction = re.sub(" > .[^ ]*?$", "", construction)
        # remove brackets
        construction = construction.replace("(", "").replace(")", "")
        # remove [insertions]
        construction = re.sub(r"^\[.*\] \+| \[.*\] \+| \+ \[.*\]$", "", construction)

        if not i.root_base:
            if construction:
                return construction
            else:
                return ""

        else:
            # cleanup the base and base_construction
            # remove types
            base_clean = re.sub(" \\(.+\\)$", "", i.root_base)
            # remove base root + sign
            base = re.sub("(.+ )(.+?$)", "\\2", base_clean)
            # remove base
            base_construction = re.sub("(.+)( > .+?$)", "\\1", base_clean)
            # remove phonetic changes
            base_construction = re.sub(" >.*", "", base_construction)

            if i.pos != "fut":
                # replace base with root + sign
                root_sign_plus = i.root_sign.replace(" ", " + ")
                root_plus_sign = f"{i.root_clean} + {root_sign_plus}"
                construction = re.sub(base, root_plus_sign, construction)
            else:
                # replace base with base construction
                construction = re.sub(base, base_construction, construction)
            return construction
    else:
        return ""


def clean_construction(construction):
    """Clean construction of all brackets and phonetic changes."""
    # strip line 2
    construction = re.sub(r"\n.+", "", construction)
    # remove > ... +
    construction = re.sub(r" >.+?( \+)", "\\1", construction)
    # remove [] ... +
    construction = re.sub(r" \+ \[.+?( \+)", "\\1", construction)
    # remove [] at beginning
    construction = re.sub(r"^\[.+?( \+ )", "", construction)
    # remove [] at end
    construction = re.sub(r" \+ \[.*\]$", "", construction)
    # remove ??
    construction = re.sub("\\?\\? ", "", construction)
    return construction


if __name__ == "__main__":
    session = get_db_session(Path("dpd.db"))
    results = (
        session.query(DpdHeadword)
        .filter(DpdHeadword.root_sign.contains(" "))
        .limit(50)
        .all()
    )
    for i in results:
        print(i.lemma_1, ": ", summarize_construction(i))

</file>


<file path="tools/niggahitas.py">
"""Add all variants of niggahita character (ŋ ṁ) to a list."""

from typing import List


def add_niggahitas(words: List[str], all=True) -> List[str]:
    """Add various types of niggahitas (ŋ ṁ) to a list."""

    for word in words:
        if "ṃ" in word:
            words += [word.replace("ṃ", "ṁ")]
            if all == True:
                words += [word.replace("ṃ", "ŋ")]

    return list(set(words))

</file>


<file path="tools/pali_sort_key.py">
"""Functions for sorting by Pāḷi alphabetical order."""

import re

letter_to_number = {
    "√": "00",
    "a": "01",
    "ā": "02",
    "i": "03",
    "ī": "04",
    "u": "05",
    "ū": "06",
    "e": "07",
    "o": "08",
    "k": "09",
    "kh": "10",
    "g": "11",
    "gh": "12",
    "ṅ": "13",
    "c": "14",
    "ch": "15",
    "j": "16",
    "jh": "17",
    "ñ": "18",
    "ṭ": "19",
    "ṭh": "20",
    "ḍ": "21",
    "ḍh": "22",
    "ṇ": "23",
    "t": "24",
    "th": "25",
    "d": "26",
    "dh": "27",
    "n": "28",
    "p": "29",
    "ph": "30",
    "b": "31",
    "bh": "32",
    "m": "33",
    "y": "34",
    "r": "35",
    "l": "36",
    "v": "37",
    "s": "38",
    "h": "39",
    "ḷ": "40",
    "ṃ": "41",
}

sanksrit_letter_to_number = {
    "√": "00",
    "a": "01",
    "ā": "02",
    "i": "03",
    "ī": "04",
    "u": "05",
    "ū": "06",
    "ṛ": "07",
    "ṝ": "08",
    "ḷ": "09",
    "ḹ": "10",
    "e": "11",
    "ai": "12",
    "o": "13",
    "au": "14",
    "ḥ": "15",
    "ṃ": "16",
    "k": "17",
    "kh": "18",
    "g": "19",
    "gh": "20",
    "ṅ": "21",
    "c": "22",
    "ch": "23",
    "j": "24",
    "jh": "25",
    "ñ": "26",
    "ṭ": "27",
    "ṭh": "28",
    "ḍ": "29",
    "ḍh": "30",
    "ṇ": "31",
    "t": "32",
    "th": "33",
    "d": "34",
    "dh": "35",
    "n": "36",
    "p": "37",
    "ph": "38",
    "b": "39",
    "bh": "40",
    "m": "41",
    "y": "42",
    "r": "43",
    "l": "44",
    "v": "45",
    "ś": "46",
    "ṣ": "47",
    "s": "48",
    "h": "49",
}


def pali_list_sorter(words: list[str] | set[str]) -> list:
    """Sort a list or a set of words in Pāḷi alphabetical order.
    Usage:
    pali_list_sorter(list_of_pali_words)"""

    if isinstance(words, set):
        words = list(words)

    if words is None:
        return []

    else:
        pattern = "|".join(key for key in letter_to_number.keys())

        def replace(match):
            return letter_to_number[match.group(0)]

        sorted_words = sorted(words, key=lambda word: re.sub(pattern, replace, word))

        return sorted_words


def pali_sort_key(word: str) -> str:
    """A key for sorting in Pāḷi alphabetical order."
    Usage:
    list = sorted(list, key=pali_sort_key)
    db = sorted(db, key=lambda x: pali_sort_key(x.lemma_1))
    df.sort_values(
        by="lemma_1", inplace=True, ignore_index=True,
        key=lambda x: x.map(pali_sort_key))"""

    pattern = "|".join(re.escape(key) for key in letter_to_number.keys())

    def replace(match):
        return letter_to_number[match.group(0)]

    if isinstance(word, int):
        return word
    else:
        return re.sub(pattern, replace, word)


def sanskrit_sort_key(word: str) -> str:
    """A key for sorting in Sanskrit alphabetical order."
    Usage:
    list = sorted(list, key=pali_sort_key)
    db = sorted(db, key=lambda x: sanskrit_sort_key(x.lemma_1))
    df.sort_values(
        by="lemma_1", inplace=True, ignore_index=True,
        key=lambda x: x.map(sanskrit_sort_key))"""

    pattern = "|".join(re.escape(key) for key in sanksrit_letter_to_number.keys())

    def replace(match):
        return sanksrit_letter_to_number[match.group(0)]

    if isinstance(word, int):
        return word
    else:
        return re.sub(pattern, replace, word)

</file>


<file path="tools/paths.py">
"""All file paths that get used in the Project."""

import os
from pathlib import Path
from typing import Optional


class ProjectPaths:
    def __init__(self, base_dir: Optional[Path] = None, create_dirs=True):
        if base_dir is None:
            # The current working directory of the shell.
            base_dir = Path(os.path.abspath("."))

        # root
        self.dpd_db_path = base_dir / "dpd.db"
        self.pyproject_path = base_dir / "pyproject.toml"

        # backup_tsv
        self.pali_root_path = base_dir / "db/backup_tsv/dpd_roots.tsv"
        self.pali_word_path = base_dir / "db/backup_tsv/dpd_headwords.tsv"
        self.sutta_info_tsv_path = base_dir / "db/backup_tsv/sutta_info.tsv"

        # db/bold_definitions
        self.bold_definitions_json_path = (
            base_dir / "db/bold_definitions/bold_definitions.json"
        )
        self.bold_definitions_tsv_path = (
            base_dir / "db/bold_definitions/bold_definitions.tsv"
        )

        # db/suttas
        self.dv_catalogue_suttas_tsv_path = (
            base_dir / "db/suttas/dv_catalogue_suttas.tsv"
        )

        # audio
        self.dpd_audio_db_path = base_dir / "audio/db/dpd_audio.db"
        self.dpd_audio_mp3_dir = base_dir / "audio/mp3s"
        self.dpd_audio_male1_dir = (
            base_dir / "audio/mp3s/Kannada_kn-m4_Neutral_0.85"
        )
        self.dpd_audio_male2_dir = (
            base_dir / "audio/mp3s/Kannada_kn-m1_Neutral_0.85"
        )
        self.dpd_audio_female1_dir = (
            base_dir / "audio/mp3s/Kannada_kn-f4_Neutral_0.85"
        )

        # exporter/kindle/
        self.epub_dir = base_dir / "exporter/kindle/epub/"
        self.kindlegen_path = base_dir / "exporter/kindle/kindlegen"

        # exporter/kindle/epub
        self.epub_abbreviations_path = (
            base_dir / "exporter/kindle/epub/OEBPS/Text/abbreviations.xhtml"
        )
        self.epub_content_opf_path = base_dir / "exporter/kindle/epub/OEBPS/content.opf"
        self.epub_text_dir = base_dir / "exporter/kindle/epub/OEBPS/Text"
        self.epub_titlepage_path = (
            base_dir / "exporter/kindle/epub/OEBPS/Text/titlepage.xhtml"
        )

        # exporter/kindle/templates
        self.ebook_abbrev_entry_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_abbreviation_entry.html"
        )
        self.ebook_content_opf_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_content_opf.html"
        )
        self.ebook_deconstructor_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_deconstructor_entry.html"
        )
        self.ebook_entry_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_entry.html"
        )
        self.ebook_example_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_example.html"
        )
        self.ebook_grammar_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_grammar.html"
        )
        self.ebook_letter_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_letter.html"
        )
        self.ebook_title_page_templ_path = (
            base_dir / "exporter/kindle/templates/ebook_titlepage.html"
        )

        # shared_data/help/
        self.abbreviations_tsv_path = base_dir / "shared_data/help/abbreviations.tsv"
        self.bibliography_tsv_path = base_dir / "shared_data/help/bibliography.tsv"
        self.help_tsv_path = base_dir / "shared_data/help/help.tsv"
        self.thanks_tsv_path = base_dir / "shared_data/help/thanks.tsv"

        # exporter/goldendict/javascript/
        self.buttons_js_path = base_dir / "exporter/goldendict/javascript/buttons.js"
        self.family_compound_json = (
            base_dir / "exporter/goldendict/javascript/family_compound_json.js"
        )
        self.family_compound_template_js = (
            base_dir / "exporter/goldendict/javascript/family_compound_template.js"
        )
        self.family_idiom_json = (
            base_dir / "exporter/goldendict/javascript/family_idiom_json.js"
        )
        self.family_idiom_template_js = (
            base_dir / "exporter/goldendict/javascript/family_idiom_template.js"
        )
        self.family_root_json = (
            base_dir / "exporter/goldendict/javascript/family_root_json.js"
        )
        self.family_root_template_js = (
            base_dir / "exporter/goldendict/javascript/family_root_template.js"
        )
        self.family_set_json = (
            base_dir / "exporter/goldendict/javascript/family_set_json.js"
        )
        self.family_set_template_js = (
            base_dir / "exporter/goldendict/javascript/family_set_template.js"
        )
        self.family_word_json = (
            base_dir / "exporter/goldendict/javascript/family_word_json.js"
        )
        self.family_word_template_js = (
            base_dir / "exporter/goldendict/javascript/family_word_template.js"
        )
        self.feedback_template_js = (
            base_dir / "exporter/goldendict/javascript/feedback_template.js"
        )
        self.frequency_template_js = (
            base_dir / "exporter/goldendict/javascript/frequency_template.js"
        )
        self.main_js_path = base_dir / "exporter/goldendict/javascript/main.js"
        self.sorter_js_path = base_dir / "exporter/goldendict/javascript/sorter.js"

        # exporter/share
        self.dpd_deconstructor_goldendict_dir = (
            base_dir / "exporter/share/dpd-deconstructor/"
        )
        self.dpd_deconstructor_goldendict_dir2 = (
            base_dir / "exporter/share/dpd-deconstructor2/"
        )
        self.dpd_epub_path = base_dir / "exporter/share/dpd-kindle.epub"
        self.dpd_goldendict_dir = base_dir / "exporter/share/dpd/"
        self.dpd_goldendict_zip_path = base_dir / "exporter/share/dpd-goldendict.zip"
        self.dpd_grammar_goldendict_dir = base_dir / "exporter/share/dpd-grammar/"
        self.dpd_mdict_zip_path = base_dir / "exporter/share/dpd-mdict.zip"
        self.dpd_mobi_path = base_dir / "exporter/share/dpd-kindle.mobi"
        self.dpd_variants_goldendict_dir = base_dir / "exporter/share/dpd-variants/"
        self.share_dir = base_dir / "exporter/share"
        self.release_notes_md_path = base_dir / "exporter/share/release_notes.md"
        self.change_log_md_path = base_dir / "exporter/share/change_log.md"
        self.dpd_txt_path = base_dir / "exporter/share/dpd.txt"
        self.dpd_txt_zip_path = base_dir / "exporter/share/dpd-txt.zip"

        # exporter/share/mdict
        self.dpd_deconstructor_mdd_path = (
            base_dir / "exporter/share/dpd-deconstructor-mdict.mdd"
        )
        self.dpd_deconstructor_mdx_path = (
            base_dir / "exporter/share/dpd-deconstructor-mdict.mdx"
        )
        self.dpd_grammar_mdd_path = base_dir / "exporter/share/dpd-grammar-mdict.mdd"
        self.dpd_grammar_mdx_path = base_dir / "exporter/share/dpd-grammar-mdict.mdx"
        self.dpd_mdd_path = base_dir / "exporter/share/dpd-mdict.mdd"
        self.dpd_mdx_path = base_dir / "exporter/share/dpd-mdict.mdx"
        self.dpd_variants_mdd_path = base_dir / "exporter/share/dpd-variants-mdict.mdd"
        self.dpd_variants_mdx_path = base_dir / "exporter/share/dpd-variants-mdict.mdx"

        # exporter/deconstructor/templates
        self.deconstructor_header_templ_path = (
            base_dir / "exporter/deconstructor/deconstructor_header.html"
        )
        self.deconstructor_templ_path = (
            base_dir / "exporter/deconstructor/deconstructor.html"
        )

        # exporter/templates
        self.button_box_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_button_box.html"
        )
        self.dpd_definition_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_definition.html"
        )
        self.dpd_header_plain_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_header_plain.html"
        )
        self.dpd_header_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_header.html"
        )
        self.example_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_example.html"
        )
        self.family_compound_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_family_compound.html"
        )
        self.family_idiom_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_family_idiom.html"
        )
        self.family_root_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_family_root.html"
        )
        self.family_set_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_family_set.html"
        )
        self.family_word_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_family_word.html"
        )
        self.feedback_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_feedback.html"
        )
        self.frequency_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_frequency.html"
        )
        self.grammar_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_grammar.html"
        )
        self.inflection_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_inflection.html"
        )
        self.root_header_templ_path = (
            base_dir / "exporter/goldendict/templates/root_header.html"
        )
        self.spelling_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_spelling_mistake.html"
        )
        self.templates_dir = base_dir / "exporter/templates"
        self.variant_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_variant_reading.html"
        )
        self.sutta_info_templ_path = (
            base_dir / "exporter/goldendict/templates/dpd_sutta_info.html"
        )

        # FIXME delete these and whatever uses them
        # exporter/jinja templates
        self.complete_word_templ_path = (
            base_dir / "exporter/templates_jinja/dpd_complete_word.html"
        )
        self.jinja_templates_dir = base_dir / "exporter/templates_jinja/"
        self.temp_html_file_path = base_dir / "temp/temp_html_file.html"

        # exporter/goldendict/templates - root
        self.root_button_templ_path = (
            base_dir / "exporter/goldendict/templates/root_buttons.html"
        )
        self.root_definition_templ_path = (
            base_dir / "exporter/goldendict/templates/root_definition.html"
        )
        self.root_families_templ_path = (
            base_dir / "exporter/goldendict/templates/root_families.html"
        )
        self.root_info_templ_path = (
            base_dir / "exporter/goldendict/templates/root_info.html"
        )
        self.root_matrix_templ_path = (
            base_dir / "exporter/goldendict/templates/root_matrix.html"
        )

        # exporter/goldendict/templates - other
        self.abbrev_templ_path = (
            base_dir / "exporter/goldendict/templates/help_abbrev.html"
        )
        self.epd_templ_path = base_dir / "exporter/goldendict/templates/epd.html"
        self.help_templ_path = base_dir / "exporter/goldendict/templates/help_help.html"

        # exporter/tpr
        self.tpr_deconstructor_tsv_path = (
            base_dir / "exporter/tpr/output/deconstructor.tsv"
        )
        self.tpr_dpd_tsv_path = base_dir / "exporter/tpr/output/dpd.tsv"
        self.tpr_i2h_tsv_path = base_dir / "exporter/tpr/output/i2h.tsv"
        self.tpr_output_dir = base_dir / "exporter/tpr/output"
        self.tpr_sql_file_path = base_dir / "exporter/tpr/output/dpd.sql"

        # exporter/grammar_dict/

        self.grammar_dict_header_templ_path = (
            base_dir / "exporter/grammar_dict/grammar_dict_header.html"
        )

        # exporter/grammar_dict/output

        self.grammar_dict_output_dir = base_dir / "exporter/grammar_dict/output"
        self.grammar_dict_output_html_dir = (
            base_dir / "exporter/grammar_dict/output/html"
        )
        self.grammar_dict_pickle_path = (
            base_dir / "exporter/grammar_dict/output/grammar_dict_pickle"
        )
        self.grammar_dict_tsv_path = (
            base_dir / "exporter/grammar_dict/output/grammar_dict.tsv"
        )

        # exporter/other_dictionaries/css
        self.cone_css_path = base_dir / "exporter/other_dictionaries/code/cone/cone.css"
        self.dppn_css_path = (
            base_dir / "exporter/other_dictionaries/code/dppn/dppn.css/"
        )
        self.dpr_css_path = base_dir / "exporter/other_dictionaries/code/dpr/dpr.css/"
        self.whitney_css_path = (
            base_dir / "exporter/other_dictionaries/code/whitney/whitney.css/"
        )

        # exporter/other_dictionaries/source
        self.bhs_source_path = (
            base_dir / "exporter/other_dictionaries/code/bhs/source/bhs.xml"
        )
        self.cone_front_matter_path = (
            base_dir
            / "exporter/other_dictionaries/code/cone/source/cone_front_matter.json"
        )
        self.cone_source_path = (
            base_dir / "exporter/other_dictionaries/code/cone/source/cone_dict.json"
        )
        self.cpd_source_path = (
            base_dir / "exporter/other_dictionaries/code/cpd/source/en-critical.json"
        )
        self.dppn_source_path = (
            base_dir / "exporter/other_dictionaries/code/dppn/source/DPPN.json"
        )
        self.dpr_source_path = (
            base_dir / "exporter/other_dictionaries/code/dpr/source/dpr.json"
        )
        self.eng_sin_source_path = (
            base_dir
            / "exporter/other_dictionaries/code/sin_eng_sin/source/english-sinhala.tab"
        )
        self.mw_source_path = (
            base_dir / "exporter/other_dictionaries/code/mw/source/mw_from_simsapa.json"
        )
        self.peu_source_path = (
            base_dir / "exporter/other_dictionaries/code/peu/source/latest.json"
        )
        self.sin_eng_source_path = (
            base_dir
            / "exporter/other_dictionaries/code/sin_eng_sin/source/sinhala-english.tab"
        )
        self.vri_source_path = (
            base_dir / "exporter/other_dictionaries/code/vri/source/vri.csv"
        )
        self.whitney_source_dir = (
            base_dir / "exporter/other_dictionaries/code/whitney/source/"
        )

        # exporter/other_dictionaries/goldendict
        self.bhs_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.cone_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.cpd_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.dpr_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.mw_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.peu_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.simsapa_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.sin_eng_sin_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.vri_gd_path = base_dir / "exporter/other_dictionaries/goldendict/vri.zip"
        self.whitney_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"
        self.dppn_gd_path = base_dir / "exporter/other_dictionaries/goldendict/"

        # exporter/other_dictionaries/json
        self.bhs_json_path = base_dir / "exporter/other_dictionaries/json/bhs.json"
        self.cone_json_path = base_dir / "exporter/other_dictionaries/json/cone.json"
        self.cpd_json_path = base_dir / "exporter/other_dictionaries/json/cpd.json"
        self.dppn_json = base_dir / "exporter/other_dictionaries/json/dppn.json"
        self.dpr_json_path = base_dir / "exporter/other_dictionaries/json/dpr.json"
        self.mw_json_path = base_dir / "exporter/other_dictionaries/json/mw.json"
        self.peu_json_path = base_dir / "exporter/other_dictionaries/json/peu.json"
        self.simsapa_json_path = (
            base_dir / "exporter/other_dictionaries/json/simsapa.json"
        )
        self.sin_eng_sin_json_path = (
            base_dir / "exporter/other_dictionaries/json/sin_eng_sin.json"
        )
        self.vri_json_path = base_dir / "exporter/other_dictionaries/json/vri.json"
        self.whitney_json_path = (
            base_dir / "exporter/other_dictionaries/json/whitney.json"
        )

        # exporter/other_dictionaries/mdict
        self.bhs_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.cone_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.cpd_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.dppn_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.dpr_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.mw_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.peu_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.simsapa_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.sin_eng_sin_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"
        self.vri_mdict_path = base_dir / "exporter/other_dictionaries/mdict/vri.mdx"
        self.whitney_mdict_path = base_dir / "exporter/other_dictionaries/mdict/"

        # exporter/pdf
        self.typst_data_path = base_dir / "exporter/pdf/typst_data.typ"
        self.typst_pdf_path = base_dir / "exporter/share/dpd.pdf"
        self.typst_lite_data_path = base_dir / "exporter/pdf/typst_data_lite.typ"
        self.typst_lite_pdf_path = base_dir / "exporter/share/dpd.pdf"
        self.typst_lite_zip_path = base_dir / "exporter/share/dpd-pdf.zip"
        self.typst_lite_abbreviations_path = (
            base_dir / "exporter/share/abbreviations.pdf"
        )

        # exporter/variants
        self.variants_header_path = base_dir / "exporter/variants/variants_header.html"

        # exporter/webapp
        self.webapp_css_path = base_dir / "exporter/webapp/static/dpd.css"
        self.webapp_templates_dir = base_dir / "exporter/webapp/templates"
        self.webapp_static_dir = base_dir / "exporter/webapp/static"
        self.webapp_js_path = base_dir / "exporter/webapp/static/dpd.js"
        self.webapp_home_simple_css_path = (
            base_dir / "exporter/webapp/static/home_simple.css"
        )
        self.webapp_home_css_path = base_dir / "exporter/webapp/static/home.css"
        self.webapp_bold_definitions_js_path = (
            base_dir / "exporter/webapp/static/bold_definitions.js"
        )
        self.webapp_logo_svg_path = base_dir / "exporter/webapp/static/dpd-logo.svg"
        self.webapp_logo_dark_svg_path = (
            base_dir / "exporter/webapp/static/dpd-logo-dark.svg"
        )
        self.webapp_app_js_path = base_dir / "exporter/webapp/static/app.js"
        self.webapp_switch_css_path = base_dir / "exporter/webapp/static/switch.css"

        # webapp template names as constants
        self.template_dpd_summary = "dpd_summary.html"
        self.template_dpd_headword = "dpd_headword.html"
        self.template_root_summary = "root_summary.html"
        self.template_root = "root.html"
        self.template_abbreviations_summary = "abbreviations_summary.html"
        self.template_abbreviations = "abbreviations.html"
        self.template_deconstructor_summary = "deconstructor_summary.html"
        self.template_deconstructor = "deconstructor.html"
        self.template_grammar_summary = "grammar_summary.html"
        self.template_grammar = "grammar.html"
        self.template_help_summary = "help_summary.html"
        self.template_help = "help.html"
        self.template_epd_summary = "epd_summary.html"
        self.template_epd = "epd.html"
        self.template_variant_summary = "variant_summary.html"
        self.template_variant = "variant.html"
        self.template_spelling_summary = "spelling_summary.html"
        self.template_spelling = "spelling.html"

        # identity/
        self.dpd_css_path = base_dir / "identity/css/dpd.css"
        self.dpd_variables_css_path = base_dir / "identity/css/dpd-variables.css"
        self.dpd_fonts_css_path = base_dir / "identity/css/dpd-fonts.css"
        self.dpd_css_and_fonts_path = base_dir / "identity/css/dpd-css-and-fonts.css"

        # identity/logo
        self.dpd_logo_svg = base_dir / "identity/logo/dpd-logo.svg"
        self.dpd_logo_dark_svg = base_dir / "identity/logo/dpd-logo-dark.svg"
        self.dpd_logo_dark_bmp = base_dir / "identity/logo/dpd-logo-dark.bmp"

        # identity/fonts
        self.fonts_dir = base_dir / "identity/fonts"

        # gui
        self.pass2_checked_path = base_dir / "gui/pass2_checked.json"

        # gui/stash
        self.daily_record_path = base_dir / "gui/stash/daily_record"
        self.example_stash_path = base_dir / "gui/stash/example"
        self.save_state_path = base_dir / "gui/stash/gui_state"
        self.stash_dir = base_dir / "gui/stash/"
        self.stash_path = base_dir / "gui/stash/stash"

        # gui2
        self.load_example_dump = base_dir / "gui2/find_words_with_examples_dump.json"

        # db/inflections/
        self.inflection_templates_path = (
            base_dir / "db/inflections/inflection_templates.xlsx"
        )

        # resources/bw/js
        self.tbw_i2h_js_path = base_dir / "resources/bw2/js/dpd_i2h.js"
        self.tbw_dpd_ebts_js_path = base_dir / "resources/bw2/js/dpd_ebts.js"
        self.tbw_deconstructor_js_path = (
            base_dir / "resources/bw2/js/dpd_deconstructor.js"
        )

        # resources/fdg_dpd
        self.fdg_i2h_js_path = (
            base_dir / "resources/fdg_dpd/assets/standalone-dpd/dpd_i2h.js"
        )
        self.fdg_dpd_ebts_js_path = (
            base_dir / "resources/fdg_dpd/assets/standalone-dpd/dpd_ebts.js"
        )
        self.fdg_deconstructor_js_path = (
            base_dir / "resources/fdg_dpd/assets/standalone-dpd/dpd_deconstructor.js"
        )

        # resources/sc-data

        self.sc_data_dir = base_dir / "resources/sc-data/sc_bilara_data/root/pli/ms/"
        self.sc_variants_dir = (
            base_dir / "resources/sc-data/sc_bilara_data/variant/pli/ms/"
        )

        self.sc_pli2en_dpd_json = (
            base_dir / "resources/sc-data/dictionaries/simple/en/pli2en_dpd.json"
        )  # final dictionary format

        # FIXME part of the old sc exporter, delete when tested
        # self.sc_data_dpd_dir = base_dir / "resources/sc-data/dpd/"

        # self.sc_i2h_js_path = base_dir / "resources/sc-data/dpd/dpd_i2h.js"
        # self.sc_i2h_json_path = base_dir / "resources/sc-data/dpd/dpd_i2h.json"

        # self.sc_dpd_ebts_js_path = base_dir / "resources/sc-data/dpd/dpd_ebts.js"
        # self.sc_dpd_ebts_json_path = base_dir / "resources/sc-data/dpd/dpd_ebts.json"

        # self.sc_deconstructor_js_path = (
        #     base_dir / "resources/sc-data/dpd/dpd_deconstructor.js"
        # )
        # self.sc_deconstructor_json_path = (
        #     base_dir / "resources/sc-data/dpd/dpd_deconstructor.json"
        # )

        # resources/syāmaraṭṭha_1927
        self.sya_dir = base_dir / "resources/syāmaraṭṭha_1927/"

        # resources/dpd_submodules/cst
        self.cst_txt_dir = base_dir / "resources/dpd_submodules/cst/romn_txt/"
        self.cst_xml_dir = base_dir / "resources/dpd_submodules/cst/romn/"

        # resources/dpd_submodules/bjt
        self.bjt_dir = base_dir / "resources/dpd_submodules/bjt/public/static/"
        self.bjt_sinhala_dir = (
            base_dir / "resources/dpd_submodules/bjt/public/static/text/"
        )
        self.bjt_roman_json_dir = (
            base_dir / "resources/dpd_submodules/bjt/public/static/roman_json/"
        )
        self.bjt_roman_txt_dir = (
            base_dir / "resources/dpd_submodules/bjt/public/static/roman_txt/"
        )
        self.bjt_books_dir = (
            base_dir / "resources/dpd_submodules/bjt/public/static/books/"
        )

        # resources/other_pali_texts
        self.other_pali_texts_dir = base_dir / "resources/other_pali_texts"

        # resources/tipitaka_translation_db
        self.tipitaka_translation_db_dir = (
            base_dir / "resources/tipitaka_translation_db"
        )
        self.tipitaka_translation_db_path = (
            base_dir / "resources/tipitaka_translation_db/tipitaka-translation-data.db"
        )
        self.tipitaka_translation_db_tarball = (
            base_dir
            / "resources/tipitaka_translation_db/tipitaka-translation-data.db.zip"
        )

        # resources/tpr
        self.tpr_beta_path = (
            base_dir / "resources/tpr_downloads/release_zips/dpd_beta.zip"
        )
        self.tpr_download_list_path = (
            base_dir
            / "resources/tpr_downloads/download_source_files/download_list.json"
        )
        self.tpr_release_path = (
            base_dir / "resources/tpr_downloads/release_zips/dpd.zip"
        )

        # resources/deconstructor_output repo
        self.deconstructor_output_json = (
            base_dir / "resources/deconstructor_output/deconstructor_output.json"
        )
        self.deconstructor_output_tar_path = (
            base_dir / "resources/deconstructor_output/deconstructor_output.json.tar.gz"
        )
        self.deconstructor_output_dir = base_dir / "resources/deconstructor_output/"

        # docs
        self.mk_docs_yaml = base_dir / "mkdocs.yaml"
        self.docs_css_path = base_dir / "docs/stylesheets/extra.css"
        self.docs_css_variables_path = base_dir / "docs/stylesheets/dpd-variables.css"
        self.docs_dir = base_dir / "docs/"
        self.docs_bibliography_md_path = base_dir / "docs/bibliography.md"
        self.docs_abbreviations_md_path = base_dir / "docs/abbreviations.md"
        self.docs_changelog_md_path = base_dir / "docs/changelog.md"
        self.docs_thanks_md_path = base_dir / "docs/thanks.md"

        # shared_data/deconstructor
        self.decon_manual_corrections = (
            base_dir / "shared_data/deconstructor/manual_corrections.tsv"
        )
        self.decon_exceptions = base_dir / "shared_data/deconstructor/exceptions.tsv"
        self.decon_checked = base_dir / "shared_data/deconstructor/checked.csv"
        self.sandhi_rules_path = base_dir / "shared_data/deconstructor/sandhi_rules.tsv"
        self.spelling_mistakes_path = (
            base_dir / "shared_data/deconstructor/spelling_mistakes.tsv"
        )
        self.variant_readings_path = (
            base_dir / "shared_data/deconstructor/variant_readings.tsv"
        )

        # db/sanskrit
        self.root_families_sanskrit_path = (
            base_dir / "db/sanskrit/root_families_sanskrit.tsv"
        )

        # share
        self.changed_headwords_path = base_dir / "shared_data/changed_headwords"
        self.headword_stem_pattern_dict_path = (
            base_dir / "shared_data/headword_stem_pattern_dict"
        )
        self.inflection_templates_pickle_path = (
            base_dir / "shared_data/inflection_templates"
        )
        self.inflections_from_translit_json_path = (
            base_dir / "shared_data/inflections_from_translit.json"
        )
        self.inflections_to_translit_json_path = (
            base_dir / "shared_data/inflections_to_translit.json"
        )
        self.lookup_from_translit_path = (
            base_dir / "shared_data/lookup_from_translit.json"
        )
        self.lookup_to_translit_path = base_dir / "shared_data/lookup_to_translit.json"
        self.template_changed_path = base_dir / "shared_data/changed_templates"

        self.user_dict_path = base_dir / "shared_data/user_dictionary.txt"

        self.additions_tsv_path = base_dir / "shared_data/additions.tsv"
        self.additions_pickle_path = base_dir / "shared_data/additions"
        self.corrections_tsv_path = base_dir / "shared_data/corrections.tsv"
        # self.deleted_words_history_pth = base_dir / "shared_data/deleted_words_history.tsv"
        self.major_change_meaning_history_pth = (
            base_dir / "shared_data/major_change_meaning_history.tsv"
        )

        # share/frequency
        self.cst_file_freq = base_dir / "shared_data/frequency/cst_file_freq.json"
        self.cst_freq_json = base_dir / "shared_data/frequency/cst_freq.json"
        self.cst_wordlist = base_dir / "shared_data/frequency/cst_wordlist.json"

        self.bjt_file_freq = base_dir / "shared_data/frequency/bjt_file_freq.json"
        self.bjt_freq_json = base_dir / "shared_data/frequency/bjt_freq.json"
        self.bjt_wordlist = base_dir / "shared_data/frequency/bjt_wordlist.json"

        self.sya_file_freq = base_dir / "shared_data/frequency/sya_file_freq.json"
        self.sya_freq_json = base_dir / "shared_data/frequency/sya_freq.json"
        self.sya_wordlist = base_dir / "shared_data/frequency/sya_wordlist.json"

        self.sc_file_freq = base_dir / "shared_data/frequency/sc_file_freq.json"
        self.sc_freq_json = base_dir / "shared_data/frequency/sc_freq.json"
        self.sc_wordlist = base_dir / "shared_data/frequency/sc_wordlist.json"

        # temp
        self.temp_dir = base_dir / "temp/"

        # tools
        self.sandhi_contractions_path = base_dir / "tools/sandhi_contractions.json"
        self.hyphenations_dict_path = base_dir / "tools/hyphenations.json"
        self.uposatha_day_ini = base_dir / "tools/uposatha_day.ini"

        # db_tests/
        self.internal_tests_path = base_dir / "db_tests/db_tests_columns.tsv"

        # db_tests/single/
        self.antonym_dict_path = base_dir / "db_tests/single/test_antonyms.json"
        self.bahubbihi_dict_path = base_dir / "db_tests/single/test_bahubbihis.json"
        self.bold_example_path = base_dir / "db_tests/single/test_bold.json"
        self.compound_type_path = base_dir / "db_tests/single/add_compound_type.tsv"
        self.digu_json_path = base_dir / "db_tests/single/test_digu.json"
        self.hyphenations_dict_path_old = (
            base_dir / "db_tests/single/test_hyphenations.json"
        )
        self.hyphenations_scratchpad_path = (
            base_dir / "db_tests/single/test_hyphenations.txt"
        )
        self.idioms_exceptions_dict = base_dir / "db_tests/single/test_idioms.json"

        self.maha_exceptions_list = (
            base_dir / "db_tests/single/test_maha_exceptions.json"
        )

        self.neg_compound_exceptions = (
            base_dir / "db_tests/single/test_neg_compound_exceptions.json"
        )
        self.phonetic_changes_path = (
            base_dir / "db_tests/single/add_phonetic_changes.tsv"
        )
        self.phonetic_changes_vowels_path = (
            base_dir / "db_tests/single/add_phonetic_changes_vowels.tsv"
        )
        self.sukha_dukkha_finder_path = (
            base_dir / "db_tests/single/test_sukha_dukkha_finder.json"
        )
        self.syn_var_exceptions_old_path = (
            base_dir / "db_tests/single/add_synonym_variant_exceptions"
        )
        self.syn_var_exceptions_path = (
            base_dir / "db_tests/single/add_synonym_variant.json"
        )
        self.wf_exceptions_list = (
            base_dir / "db_tests/single/add_word_family_exceptions"
        )

        # db_tests_gui
        self.add_antonyms_sync_dict = (
            base_dir / "db_tests_gui/add_antonyms_sync_dict.json"
        )

        # .. external
        self.old_dpd_full_path = base_dir / "../csvs/dpd-full.csv"
        self.old_roots_csv_path = base_dir / "../csvs/roots.csv"

        # go_modules
        self.go_deconstructor_output_dir = base_dir / "go_modules/deconstructor/output"
        self.go_deconstructor_output_json = (
            base_dir / "go_modules/deconstructor/output/deconstructor_output.json"
        )

        if create_dirs:
            self.create_dirs()

    def create_dirs(self):
        for d in [
            self.bjt_books_dir,
            self.bjt_roman_json_dir,
            self.bjt_roman_txt_dir,
            self.cst_txt_dir,
            self.epub_text_dir,
            self.go_deconstructor_output_dir,
            self.grammar_dict_output_dir,
            self.grammar_dict_output_html_dir,
            self.share_dir,
            self.stash_dir,
            self.temp_dir,
            self.tpr_output_dir,
        ]:
            d.mkdir(parents=True, exist_ok=True)

</file>


<file path="tools/pos.py">
"""Categorizing parts of speech (pos) into various lists."""

INDECLINABLES = [
    "abbrev",
    "abs",
    "ger",
    "ind",
    "inf",
    "prefix",
    "sandhi",
    "suffix",
    "idiom",
    "var",
]

CONJUGATIONS = ["aor", "cond", "fut", "imp", "imperf", "opt", "perf", "pr"]

DECLENSIONS = [
    "adj",
    "card",
    "cs",
    "fem",
    "letter",
    "masc",
    "nt",
    "ordin",
    "pp",
    "pron",
    "prp",
    "ptp",
    "root",
    "ve",
]

POS = [
    "abbrev",
    "abs",
    "adj",
    "aor",
    "card",
    "cond",
    "cs",
    "fem",
    "fut",
    "ger",
    "idiom",
    "imp",
    "imperf",
    "ind",
    "inf",
    "letter",
    "masc",
    "nt",
    "opt",
    "ordin",
    "perf",
    "pp",
    "pr",
    "prefix",
    "pron",
    "prp",
    "ptp",
    "root",
    "sandhi",
    "suffix",
    "ve",
]

VERBS = [
    "abs",
    "aor",
    "cond",
    "fut",
    "ger",
    "imp",
    "imperf",
    "inf",
    "opt",
    "perf",
    "pp",
    "pr",
    "prp",
    "ptp",
]

PARTICIPLES = [
    "pp",
    "prp",
    "ptp",
]

NOUNS = [
    "fem",
    "masc",
    "nt",
]

EXCLUDE_FROM_FREQ: set = {
    "abbrev",
    "cs",
    "idiom",
    "letter",
    "prefix",
    "root",
    "suffix",
    "ve",
}

</file>


<file path="tools/printer.py">
"""Utilities for colored console output with timing and structured TSV logging."""

import logging
from datetime import datetime
import time
from pathlib import Path
from rich import print
from typing import Union, Optional, ClassVar


class TSVFormatter(logging.Formatter):
    """Format log records as TSV with headers."""

    FIELDS = [
        "timestamp",
        "level",
        "operation",
        "type",  # title, status, success, error, etc
        "message",  # original message
        "elapsed",  # timing from bop()
        "count",  # for numerical outputs
        "session",  # to group related operations
    ]

    def __init__(self):
        super().__init__()
        self.header_written = False

    def format(self, record):
        # Write header on first use
        if not self.header_written:
            self.header_written = True
            return "\t".join(self.FIELDS)

        # Add extra fields to record
        for k, v in record.__dict__.get("extra", {}).items():
            setattr(record, k, v)

        # Extract values for each field
        values = []
        for field in self.FIELDS:
            if field == "timestamp":
                values.append(self.formatTime(record))
            elif field == "level":
                values.append(record.levelname)
            elif field == "message":
                values.append(record.getMessage())
            else:
                # Get fields from record attributes
                values.append(str(getattr(record, field, "")))

        return "\t".join(values)


class Printer:
    """Colored console output with timing and TSV logging."""

    def __init__(self, log_file: Optional[Path] = None):
        self.line = "-" * 40
        self.start_time: float | None = None
        self.session = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Set up logging if log_file provided
        self.logger = None
        if log_file:
            self.logger = logging.getLogger("dpd")
            self.logger.setLevel(logging.INFO)

            # File handler with TSV formatting
            handler = logging.FileHandler(log_file)
            handler.setFormatter(TSVFormatter())
            self.logger.addHandler(handler)

    def _log(self, level: int, operation: str, msg: str, **kwargs) -> None:
        """Log with additional context if logging is enabled."""
        if self.logger:
            # Create dictionary of extra fields
            extra = {"operation": operation, "session": self.session}

            # Add timing if available
            if self.start_time is not None:
                extra["elapsed"] = self.bop()

            # Add any additional kwargs
            extra.update(kwargs)

            # Log with extra fields
            self.logger.log(level, msg, extra=extra)

    # Class variable for main timer
    _ticx: ClassVar[datetime | None] = None

    @classmethod
    def tic(cls) -> None:
        """Start the main clock."""
        cls._ticx = datetime.now()

    @classmethod
    def toc(cls) -> None:
        """Stop the main clock and print elapsed time."""
        if cls._ticx is None:
            print("[red]Error: tic() not called before toc()[/red]")
            return

        tocx = datetime.now()
        tictoc = tocx - cls._ticx
        print("[cyan]" + ("-" * 40))
        print(f"[cyan]{tictoc}")
        print()

    def bip(self) -> None:
        """Start a mini clock."""
        self.start_time = time.time()

    def bop(self) -> str:
        """End mini clock and return elapsed time."""
        if self.start_time is None:
            return "0.000"
        elapsed_time = time.time() - self.start_time
        return f"{elapsed_time:.3f}"

    def print_bop(self) -> None:
        """Print the elapsed time right-aligned."""
        print(f"{self.bop():>10}")

    # Printer methods
    def title(self, text: str) -> None:
        """Print bright yellow title and start timer."""
        print(f"[bright_yellow]{text}")
        self.bip()
        self._log(logging.INFO, "title", text, type="title")

    def green_title(self, message: str) -> None:
        """Print green title and start timer."""
        print(f"[green]{message}")
        self.bip()
        self._log(logging.INFO, "green_title", message, type="title")

    def green(self, message: str) -> None:
        """Print left-aligned green message and start timer."""
        print(f"[green]{message:<35}", end="")
        self.bip()
        self._log(logging.INFO, "status", message, type="status")

    def cyan(self, message: str) -> None:
        """Print left-aligned cyan message and start timer."""
        print(f"[cyan]{message:<35}", end="")
        self.bip()
        self._log(logging.INFO, "status", message, type="status")

    def white(self, message: str) -> None:
        """Print indented white message and start timer."""
        print(f"{'':<5}[white]{message:<30}", end="")
        self.bip()
        self._log(logging.INFO, "info", message, type="info")

    def yes(self, message: Union[int, str]) -> None:
        """Print right-aligned blue message with timing."""
        if isinstance(message, int):
            formatted = f"{message:>10,}"
            self._log(
                logging.INFO, "success", str(message), type="success", count=message
            )
        else:
            formatted = f"{message:>10}"
            self._log(logging.INFO, "success", message, type="success")
        print(f"[blue]{formatted}", end="")
        self.print_bop()

    def no(self, message: Union[int, str]) -> None:
        """Print right-aligned red message with timing."""
        print(f"[red]{message:>10}", end="")
        self.print_bop()
        self._log(logging.WARNING, "failure", str(message), type="failure")

    def red(self, message: str) -> None:
        """Print red message."""
        print(f"[red]{message}")
        self._log(logging.ERROR, "error", message, type="error")

    def counter(self, counter: int, total: int, word: str) -> None:
        """Print progress counter with timing."""
        print(f"{counter:>10,} / {total:<10,} {word[:20]:<20} {self.bop():>10}")
        self.bip()
        self._log(
            logging.INFO, "counter", word, type="progress", count=counter, total=total
        )

    def summary(self, key: str, value: str | int) -> None:
        """Print key-value summary in green."""
        print(f"[green]{key:<20}[/green]{value}")
        self._log(logging.INFO, "summary", f"{key}: {value}", type="summary", key=key)

    # basic logging messages

    def info(self, message: str) -> None:
        """Print green message."""

        print(f"[green]{message}")
        self._log(logging.INFO, "info", message, type="info")

    def warning(self, message: str) -> None:
        """Print amber message."""

        print(f"[yellow]{message}")
        self._log(logging.WARNING, "warning", message, type="warning")

    def error(self, message: str) -> None:
        """Print red message."""

        print(f"[red]{message}")
        self._log(logging.ERROR, "error", message, type="error")


# Create singleton instance with optional log file
printer = Printer(Path("dpd_operations.log"))

</file>


<file path="tools/sinhala_tools.py">
from aksharamukha import transliterate

pos_dict = {
    "letter": {"pos_si": "අ", "pos_si_full": "අකුර"},
    "prefix": {"pos_si": "උප", "pos_si_full": "උපසර්ග"},
    "cs": {"pos_si": "විප්‍ර", "pos_si_full": "විකරණ ප්‍රත්‍යය"},
    "abbrev": {"pos_si": "කෙටියෙ", "pos_si_full": "කෙටි යෙදුම්"},
    "adj": {"pos_si": "විශේ", "pos_si_full": "විශෙෂණ පද"},
    "pron": {"pos_si": "සර්", "pos_si_full": "සර්වනාම"},
    "ptp": {"pos_si": "කි", "pos_si_full": "කිතක/කිච්ච ප්‍රත්‍යය"},
    "pp": {"pos_si": "අකෘ", "pos_si_full": "අතීත කෘදන්ත"},
    "masc": {"pos_si": "පු", "pos_si_full": "පුල්ලිංග"},
    "aor": {"pos_si": "අතී", "pos_si_full": "අජ්ජතනී, අතීත කාළ"},
    "nt": {"pos_si": "න", "pos_si_full": "නපුංසක ලිංග"},
    "fem": {"pos_si": "ඉ", "pos_si_full": "ඉත්ථි ලිංග"},
    "ind": {"pos_si": "නි", "pos_si_full": "නිපාත. අව්‍ය පද"},
    "prp": {"pos_si": "මික්‍රි", "pos_si_full": "මිශ්‍ර ක්‍රියා"},
    "abs": {"pos_si": "පූ", "pos_si_full": "පූර්ව ක්‍රියා"},
    "cond": {"pos_si": "කා", "pos_si_full": "කාලාතිපත්ති,සත්තමී"},
    "imperf": {"pos_si": "අකා", "pos_si_full": "අතීත කාළ/හීයත්තනී"},
    "sandhi": {"pos_si": "සන්ධි", "pos_si_full": "සන්ධි"},
    "idiom": {"pos_si": "භා", "pos_si_full": "භාෂා රීතියට අනුගත පද"},
    "pr": {"pos_si": "වකා", "pos_si_full": "වර්තමාන කාළ"},
    "inf": {"pos_si": "අව්‍ය", "pos_si_full": "තුමන්ත,අව්‍ය"},
    "ger": {"pos_si": "භාව", "pos_si_full": "අව්‍යය, භාව පද"},
    "card": {"pos_si": "සං", "pos_si_full": "සංඛ්‍යා ශබ්ද"},
    "ordin": {"pos_si": "සං.පූ", "pos_si_full": "සංඛ්‍යා පූරණ ශබ්ද"},
    "imp": {"pos_si": "වික්‍රි", "pos_si_full": "පඤ්චමී/විධි ක්‍රියා"},
    "opt": {"pos_si": "සත්", "pos_si_full": "ඉච්ඡිතාර්ථය,සත්තමී"},
    "ve": {"pos_si": "වාච්‍ය", "pos_si_full": "වාච්‍ය"},
    "root": {"pos_si": "ධාතුව", "pos_si_full": "ධාතුව"},
    "suffix": {"pos_si": "ප්‍රත්‍ය", "pos_si_full": "ප්‍රත්‍ය"},
    "perf": {"pos_si": "පරො", "pos_si_full": "පරොක්ඛා "},
    "fut": {"pos_si": "අකා", "pos_si_full": "අනාගත කාළ"},
}


def pos_si(pos: str):
    return pos_dict[pos]["pos_si"]


def pos_si_full(pos: str):
    return pos_dict[pos]["pos_si_full"]


def translit_ro_to_si(text: str) -> str:
    return transliterate.process(
        "IASTPali",
        "Sinhala",
        text,
        post_options=["SinhalaPali", "SinhalaConjuncts"],
    )  # type:ignore


def translit_si_to_ro(text: str) -> str:
    text_translit = transliterate.process(
        "Sinhala",
        "IASTPali",
        text,
        post_options=["SinhalaPali", "SinhalaConjuncts"],
    )  # type:ignore

    text_translit = (
        text_translit.replace("ï", "i")
        .replace("ü", "u")
        .replace("ĕ", "e")
        .replace("ŏ", "o")
    )

    return text_translit


gram_dict = {
    "nom": "පඨමා",
    "acc": "දුතියා",
    "instr": "තතියා",
    "dat": "චතුත්ථී",
    "abl": "පඤ්චමී",
    "gen": "ඡට්ඨි",
    "loc": "සත්තමී",
    "voc": "ආලපන",
    "In comps": "සන්ධිවල",
    "fem sg": "ඉ ඒක",
    "fem pl": "ඉ බහු",
    "masc sg": "පු ඒක",
    "masc pl": "පු බහු",
    "neut sg": "න ඒක",
    "neut pl": "න බහු",
    "declension, conjugation": "වරනැගීම",
    "sg": "ඒක",
    "pl ": "බහු",
    "reflexive sg": "අත්තනො ඒක",
    "reflexive pl": "අත්තනො බහු",
    "pr  3rd": "වත් පඨ",
    "pr 2nd": "වත් මජ්",
    "pr 1st": "වත් උත්",
    "imp 3rd": "පඤ් පඨ",
    "imp 2nd": "පඤ් මජ්",
    "imp 1st": "පඤ් උත්",
    "opt 3rd": "සත් පඨ",
    "opt 2nd": "සත් මජ්",
    "opt 1st": "සත් උත්",
    "fut 3rd": "භවි පඨ",
    "fut 2nd": "භවි මජ්",
    "fut 1st": "භවි උත්",
    "aor 3rd": "අජ් පඨ",
    "aor 2nd": "අජ් මජ්",
    "aor 1st": "අජ් උත්",
    "pref 3rd": "පරො පඨ",
    "pref 2nd": "පරො මජ්",
    "pref 1st": "පරො උත්",
    "cond 3rd": "කාලාති පඨ",
    "cond 2nd": "කාලාති මජ්",
    "cond 1st": "කාලාති උත්",
    "Imperf 3rd": "හීය පඨ",
    "Imperf 2nd": "හීය මජ්",
    "Imperf 1st": "හීය උත්",
    "1st sg": "උත් ඒක ",
    "1st pl": "උත් බහු",
    "pron": "සර්",
    "subject": "කර්තෘ",
    "object": "කර්මය",
    "2nd sg": "මජ් ඒක",
    "2nd pl": "මජ් බහු",
    "3rd sg": "පඨ ඒක ",
    "3rd pl": "පඨ බහු",
    "Inflections not found in the Chaṭṭha Saṅgāyana corpus, or within processed sandhi compounds are grayed out. They might still occur elsewhere, within compounds or in other versions of the Pāḷi texts.": " ඡට්ඨ සංගායනා ත්‍රිපිටකයෙහි පද හෝ සන්ධි පද තුළ දක්නට නොලැබෙන  පද අළු පැහැයෙන් යුක්ත වේ. ඒවා  වෙනත්  පොත්වල හෝ සන්ධි තුළ හෝ වෙනත් ත්‍රිපිටක අනුවාදවල තිබිය හැක.",
    "Did you spot a mistake in the declension table? Something missing? Report it here.": "වරනැගීම් වගුවේ වැරැද්දක් ඔබ දුටුවාද? යමක් අඩු වී තිබේද? එය මෙතනින් වාර්තා කරන්න.",
    "Abbreviation": "කෙටි යෙදුම",
    "Meaning": "තේරුම",
    "Pāḷi": "පාලි",
    "Example": "උදාහරණ",
    "Information": "තොරතුරු",
    "Nominative case": "පඨමා විභත්ති",
    "Paṭhamā, paccattavacana": "පඨමා, පච්චත්තවචන",
    "The category of nouns serving as the grammatical subject of a verb": "ක්‍රියා පදයට විෂය වන පදය හෙවත් උක්ත පද කාණ්ඩය",
    "Present tense": "වර්තමාන කාලය",
    "past tense": "අතීත කාලය",
    "future tense": "අනාගත කාලය",
    "A verb tense that expresses actions or states at the time of speaking (e.g. lives; appears; sees)": "මේ මොහොතේදී සිදුවන ක්‍රියාවක් හෝ සිදුවීමක් ප්‍රකාශ කරන ක්‍රියා පදය (උදා: ජීවත්වෙයි; දිස්වේ; දකී)",
    "Aorist verb": "අතීත කාල ක්‍රියාව",
    "A form of a verb that, in the indicative mood, expresses past action. (e.g. was; sat down; arose)": "ක්‍රියා පදයක ආකාරයක්, අතීත ක්‍රියාව ප්‍රකාශ කරයි. (උදා. විය, වාඩිවිය, පැන නැගුණි)",
    "Accusative case": "දුතියා විභත්ති",
    "The object of the sentence (e.g. me)": "වාක්‍යයේ කර්මය (උදා: මම)",
    "Dutiyā, upayogavacana, kammavacana": "දුතියා, උපයොගවචන, කම්මවචන",
}


def si_grammar(text) -> str:
    if text in gram_dict:
        return gram_dict[text]
    else:
        return text

</file>


<file path="tools/sutta_codes.py">
""" "Return a list of sutta codes"""

import re

from db.models import SuttaInfo
from tools.pali_sort_key import pali_list_sorter


def generate_range_of_sutta_codes(code_with_dash: str) -> list[str]:
    if "." in code_with_dash:
        # find the base of the code, 'SN12.' in 'SN12.5-8'
        code_base = re.sub(r"(?<=\.).+", "", code_with_dash)
    else:
        # if no '.' e.g. DHP1-20 return early
        return []

    # find the part with dashes, '5-8.' in 'SN12.5-8'
    code_dash = re.sub(code_base, "", code_with_dash)

    # find the first digit, 5 in 'SN12.5-8'
    code_first = int(re.sub(r"-.+", "", code_dash))

    # find the last digit, 8 in 'SN12.5-8'
    code_last = int(re.sub(r".+-", "", code_dash))

    sutta_code_list = []
    for num in range(code_first, code_last + 1):
        sutta_code_list.append(f"{code_base}{num}")
    return sutta_code_list


def make_list_of_sutta_codes(su: SuttaInfo) -> list[str]:
    sutta_codes_set: set[str] = set()
    sutta_codes_set.add(su.dpd_code)
    if "-" in su.dpd_code:
        sutta_codes_set.update(generate_range_of_sutta_codes(su.dpd_code))
    sutta_codes_set.add(su.sc_code)
    if "-" in su.sc_code:
        sutta_codes_set.update(generate_range_of_sutta_codes(su.sc_code))

    return pali_list_sorter(sutta_codes_set)


if __name__ == "__main__":
    su = SuttaInfo()
    su.dpd_code = "SN12.34-47"
    su.sc_code = "SN12.33-46"
    results = make_list_of_sutta_codes(su)
    print(results)

</file>


<file path="tools/utils.py">
from typing import List, TypedDict


class RenderedSizes(TypedDict):
    dpd_header: int
    dpd_summary: int
    dpd_button_box: int
    dpd_grammar: int
    dpd_example: int
    dpd_inflection_table: int
    dpd_family_root: int
    dpd_family_word: int
    dpd_family_compound: int
    dpd_family_idiom: int
    dpd_family_sets: int
    dpd_frequency: int
    dpd_feedback: int
    dpd_synonyms: int

    root_definition: int
    root_buttons: int
    root_info: int
    root_matrix: int
    root_families: int
    root_synonyms: int

    variant_readings: int
    variant_synonyms: int

    spelling_mistakes: int
    spelling_synonyms: int

    epd_header: int
    epd: int

    help: int


def default_rendered_sizes() -> RenderedSizes:
    return RenderedSizes(
        dpd_header=0,
        dpd_summary=0,
        dpd_button_box=0,
        dpd_grammar=0,
        dpd_example=0,
        dpd_inflection_table=0,
        dpd_family_root=0,
        dpd_family_word=0,
        dpd_family_compound=0,
        dpd_family_idiom=0,
        dpd_family_sets=0,
        dpd_frequency=0,
        dpd_feedback=0,
        dpd_synonyms=0,
        root_definition=0,
        root_buttons=0,
        root_info=0,
        root_matrix=0,
        root_families=0,
        root_synonyms=0,
        variant_readings=0,
        variant_synonyms=0,
        spelling_mistakes=0,
        spelling_synonyms=0,
        epd_header=0,
        epd=0,
        help=0,
    )


def sum_rendered_sizes(sizes: List[RenderedSizes]) -> RenderedSizes:
    res = default_rendered_sizes()
    for i in sizes:
        for k, v in i.items():
            res[k] += v
    return res


def list_into_batches(input_list: List, num_batches: int) -> List[List]:
    """Splits a list into a number of lists.

    When the division has remainder, this results in num + 1 batches, where the
    last batch has a small number of items, i.e. the remainder of the integer
    division.
    """

    batch_size = len(input_list) // num_batches

    if batch_size == 0:
        return [input_list]

    return [
        input_list[i : i + batch_size] for i in range(0, len(input_list), batch_size)
    ]


def squash_whitespaces(string: str) -> str:
    """
    Delete whitespace and newline chars from both sides of an every line of string
    """
    result = []
    for i in string.split("\n"):
        result.append(i.strip())
    return "".join(result)

</file>
